{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_37F7RTQrfu"
      },
      "source": [
        "Importing all the necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DYTe594MQrfv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, UpSampling2D, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from google.colab.patches import cv2_imshow\n",
        "# from guidedfilter import guided_filter\n",
        "# import BM3D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVNZFu-QQrfw"
      },
      "source": [
        "Paths to various folders and files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2exPnkgaQrfy"
      },
      "outputs": [],
      "source": [
        "path = '/Users/rohitramesh4547gmail.com/Desktop/IITG/Semester-7/BTP/Good_Illumination_Images'\n",
        "store_path = '/Users/rohitramesh4547gmail.com/Desktop/IITG/Semester-7/BTP/Darkened_Images_0.2'\n",
        "fold_path = '/Users/rohitramesh4547gmail.com/Desktop/IITG/Semester-7/BTP'\n",
        "enhanced_path = '/Users/rohitramesh4547gmail.com/Desktop/IITG/Semester-7/BTP/Enhanced_Images_Histogram_Equalization'\n",
        "test_path = fold_path + '/test_dark.jpeg'\n",
        "path = '/content/drive/MyDrive/Illumination_Enhancement_BTP/Good_Illumination_Images'\n",
        "store_path_1 = '/content/drive/MyDrive/Illumination_Enhancement_BTP/Darkened_Images_0.1'\n",
        "store_path_2 = '/content/drive/MyDrive/Illumination_Enhancement_BTP/Darkened_Images_0.2'\n",
        "store_path_3 = '/content/drive/MyDrive/Illumination_Enhancement_BTP/Darkened_Images_0.3'\n",
        "rain_path = '/content/drive/MyDrive/Illumination_Enhancement_BTP/Rain_Images'\n",
        "snow_path = '/content/drive/MyDrive/Illumination_Enhancement_BTP/Snow_Images'\n",
        "ltsitd_long_path = '/content/drive/MyDrive/Illumination_Enhancement_BTP/LTSITD/long_jpeg'\n",
        "ltsitd_short_path = '/content/drive/MyDrive/Illumination_Enhancement_BTP/LTSITD/short_jpeg'\n",
        "all_im_path = '../input/btp-dataset'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mr6_jBLQrf0"
      },
      "source": [
        "For Google Colab Only!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drUymHB8Qrf1",
        "outputId": "2369fd0f-8a22-4493-c214-72b625a0791e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AKa0ty6Qrf2"
      },
      "source": [
        "Saving images in Darkened_Images_0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osIG4JgbQrf2"
      },
      "outputs": [],
      "source": [
        "for file_name in os.listdir(path):\n",
        "    try:\n",
        "        img = Image.open(path + '/' + file_name)\n",
        "        enhancer = ImageEnhance.Brightness(img)\n",
        "        factor = 0.2\n",
        "        im_output = enhancer.enhance(factor)\n",
        "        im_output.save(store_path_2 + '/darkened_' + file_name)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Bright/Dark Channel Prior Method"
      ],
      "metadata": {
        "id": "swSPLHjyRcoC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACWkh2JFQrf4"
      },
      "outputs": [],
      "source": [
        "def get_illumination_channel(I, w):\n",
        "    M, N, _ = I.shape\n",
        "    padded = np.pad(I, ((int(w/2), int(w/2)),\n",
        "                        (int(w/2), int(w/2)), (0, 0)), 'edge')\n",
        "    darkch = np.zeros((M, N))\n",
        "    brightch = np.zeros((M, N))\n",
        "    for i, j in np.ndindex(darkch.shape):\n",
        "        # dark channel\n",
        "        darkch[i, j] = np.min(padded[i:i + w, j:j + w, :])\n",
        "        # bright channel\n",
        "        brightch[i, j] = np.max(padded[i:i + w, j:j + w, :]) \n",
        "    return darkch, brightch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMDQJuOxQrf5"
      },
      "outputs": [],
      "source": [
        "darkch, brightch = get_illumination_channel(test_image_1, 5)\n",
        "cv2.imwrite('darkch.jpeg', darkch)\n",
        "cv2.imwrite('brightch.jpeg', brightch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0whJh0n6Qrf5"
      },
      "outputs": [],
      "source": [
        "def get_atmosphere(I, brightch, p=0.1):\n",
        "    M, N = brightch.shape\n",
        "    flatI = I.reshape(M*N, 3) # reshaping image array\n",
        "    flatbright = brightch.ravel() #flattening image array\n",
        "    # sorting and slicing\n",
        "    searchidx = (-flatbright).argsort()[:int(M*N*p)] \n",
        "    A = np.mean(flatI.take(searchidx, axis=0),\n",
        "                dtype=np.float64, axis=0)\n",
        "    return A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtNqui_5Qrf6"
      },
      "outputs": [],
      "source": [
        "A = get_atmosphere(test_image_1, brightch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiLjKb_eQrf6"
      },
      "outputs": [],
      "source": [
        "def get_initial_transmission(A, brightch):\n",
        "    A_c = np.max(A) / 255\n",
        "    # finding initial transmission map\n",
        "    init_t = (brightch - A_c) / (1. - A_c) \n",
        "    return init_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSfTUqaSQrf7"
      },
      "outputs": [],
      "source": [
        "init_map = get_initial_transmission(A, brightch)\n",
        "cv2.imwrite('init_map.jpeg', init_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXBUTxbBQrf7"
      },
      "outputs": [],
      "source": [
        "def get_corrected_transmission(I, A, darkch, brightch,\n",
        "                               init_t, alpha, omega, w):\n",
        "    im = np.empty(I.shape, I.dtype);\n",
        "    for ind in range(0, 3):\n",
        "        #divide pixel values by atmospheric light\n",
        "        im[:, :, ind] = I[:, :, ind] / A[ind]\n",
        "    # dark channel transmission map\n",
        "    dark_c, _ = get_illumination_channel(im, w)\n",
        "    # corrected dark transmission map\n",
        "    dark_t = 1 - omega * dark_c \n",
        "    # initializing corrected transmission map\n",
        "    # with initial transmission map\n",
        "    corrected_t = init_t\n",
        "    # difference between transmission maps\n",
        "    diffch = brightch - darkch \n",
        "    for i in range(diffch.shape[0]):\n",
        "        for j in range(diffch.shape[1]):\n",
        "            if(diffch[i, j] < alpha):\n",
        "                corrected_t[i, j] = dark_t[i, j] * init_t[i, j]\n",
        "    return np.abs(corrected_t)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corrected_map = get_corrected_transmission(test_image_1, A,\n",
        "                                           darkch, brightch,\n",
        "                                           init_map, 0.4, 0.75, 5)\n",
        "cv2.imwrite('corrected_map.jpeg', corrected_map)"
      ],
      "metadata": {
        "id": "lggMTUhjVGOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Kc9EOpSQrf8"
      },
      "outputs": [],
      "source": [
        "def get_final_image(I, A, refined_t, tmin):\n",
        "    # duplicating the channel of 2D refined map to 3 channels\n",
        "    refined_t_broadcasted = np.broadcast_to(refined_t[:, :, None],\n",
        "                                            (refined_t.shape[0],\n",
        "                                             refined_t.shape[1], 3)) \n",
        "    J = ((I - A) / (np.where(refined_t_broadcasted < tmin,\n",
        "                             tmin, refined_t_broadcasted))) \n",
        "\n",
        "    # normalized image\n",
        "    return (J - np.min(J))/(np.max(J) - np.min(J)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGqsz0r4Qrf8"
      },
      "outputs": [],
      "source": [
        "final = get_final_image(test_image_1, A, corrected_map, 0.1)\n",
        "final = (final * 255).astype(np.uint8)\n",
        "cv2.imwrite('final.jpeg', final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-k9_vY2WQrf9"
      },
      "outputs": [],
      "source": [
        "def reduce_init_t(init_t):\n",
        "    init_t = (init_t*255).astype(np.uint8) \n",
        "    xp = [0, 32, 255]\n",
        "    fp = [0, 32, 48]\n",
        "    x = np.arange(256) # creating array [0,...,255]\n",
        "    # interpreting fp according to xp in range of x\n",
        "    table = np.interp(x, xp, fp).astype('uint8') \n",
        "    init_t = cv2.LUT(init_t, table) # lookup table\n",
        "    # normalizing the transmission map\n",
        "    init_t = init_t.astype(np.float64)/255 \n",
        "    return init_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGx1_bZqQrf9"
      },
      "outputs": [],
      "source": [
        "def dehaze(im, tmin=0.1, w=5, alpha=0.4, omega=0.75,\n",
        "           p=0.1, eps=1e-3, reduce=False):\n",
        "    # Convert the input to a float array.\n",
        "    I = np.asarray(im, dtype=np.float64) \n",
        "    I = I[:, :, :3] / 255\n",
        "    m, n, _ = I.shape\n",
        "    Idark, Ibright = get_illumination_channel(I, w)\n",
        "    A = get_atmosphere(I, Ibright, p)\n",
        "    # print(\"Obtained atmosphere lighting\")\n",
        "    init_t = get_initial_transmission(A, Ibright) \n",
        "    # print(\"Obtained initial transmission map\")\n",
        "    if reduce:\n",
        "        init_t = reduce_init_t(init_t)\n",
        "        # print(\"Obtained reduced transmission map\")\n",
        "    corrected_t = get_corrected_transmission(I, A,\n",
        "                                             Idark, Ibright,\n",
        "                                             init_t, alpha, omega, w)\n",
        "    # print(\"Obtained corrected transmission map\")\n",
        "    normI = (I - I.min()) / (I.max() - I.min())\n",
        "    # applying guided filter\n",
        "    refined_t = guided_filter(normI, corrected_t, w, eps) \n",
        "    # print(\"Obtained image after applying guided filter\")\n",
        "    \n",
        "    J_refined = get_final_image(I, A, refined_t, tmin)\n",
        "    # print(\"Obtained final image before enhancement\")\n",
        "    \n",
        "    enhanced = (J_refined * 255).astype(np.uint8)\n",
        "    f_enhanced = cv2.detailEnhance(enhanced, sigma_s=10,\n",
        "                                   sigma_r=0.15)\n",
        "    f_enhanced = cv2.edgePreservingFilter(f_enhanced,\n",
        "                                          flags=1, sigma_s=64,\n",
        "                                          sigma_r=0.2)\n",
        "    return f_enhanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsrFB9YAQrf9",
        "outputId": "374fa968-d70c-4126-9dbd-16552469b665"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "f_enhanced = dehaze(test_image_1, tmin=0.1, w=5,\n",
        "                    alpha=0.4, omega=0.75, p=0.1, eps=1e-3,\n",
        "                    reduce=False)\n",
        "cv2.imwrite('enhanced_1.jpeg', f_enhanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qkMv4YDQrf-"
      },
      "source": [
        "Pixel Enhancement Method (Increasing value in HSV image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inChHzWIQrf-"
      },
      "outputs": [],
      "source": [
        "def increase_brightness(img, value):\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    hsv[:, :, 2] += value\n",
        "    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQHxxh6vQrf-",
        "outputId": "c5683e29-e213-4be0-ab7c-07edde7e2390"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "pixel_enhanced = increase_brightness(test_image_1, 50)\n",
        "cv2.imwrite('/content/pixel_enhanced.jpeg', pixel_enhanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JHUBf17Qrf-"
      },
      "source": [
        "Gamma Correction Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvquZS4XQrf-"
      },
      "outputs": [],
      "source": [
        "def increase_contrast_brightness(img, alpha, beta, gamma):\n",
        "    new_image = np.zeros(img.shape, img.dtype)\n",
        "    for y in range(img.shape[0]):\n",
        "        for x in range(img.shape[1]):\n",
        "            for c in range(img.shape[2]):\n",
        "                new_image[y, x, c] = np.clip(alpha * img[y, x, c] + beta,\n",
        "                                             0, 255)\n",
        "    lookUpTable = np.empty((1, 256), np.uint8)\n",
        "    for i in range(256):\n",
        "        lookUpTable[0, i] = np.clip(pow(i / 255.0, gamma) * 255.0,\n",
        "                                    0, 255)\n",
        "    res = cv2.LUT(new_image, lookUpTable)\n",
        "    return new_image, res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cXzRcjZQrf_",
        "outputId": "0e7320d6-caea-4b6b-ae67-e6c0de011644"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "image_linear_transform, gamma_corrected = increase_contrast_brightness(\n",
        "    test_image_1, 2.2, 50, 0.4)\n",
        "cv2.imwrite('/content/gamma_corrected.jpeg', gamma_corrected)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o87WFfaWQrf_"
      },
      "source": [
        "Histogram Equalization Method and CLAHE Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "dbTe5gqAQrf_",
        "outputId": "a2aed5eb-17ca-495e-ddc9-351acd84faa0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEDCAYAAADKhpQUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAP60lEQVR4nO3df6xfd13H8eeLdsMEJggtZFk7WrBTG37O61iUwBTUtn+sEpFsQUHT0H8YwQjEEoyQ8dcwoiEpYJVljMjm+CE2KhbFmRmgc7eylXXLRtnQtU5axhgaIqPy9o/vqftyud/7/bb33Pu9/dznI7m533M+n37P+3xy7ivn+znne5qqQpLUhidNuwBJUn8MdUlqiKEuSQ0x1CWpIYa6JDXEUJekhkw11JNcn+REkrsn7P/aJPckOZLkY0tdnySdazLN+9STvBz4b+DGqnr+mL5bgFuAX6iqR5M8q6pOLEedknSumOqZelXdBnxzeF2S5yX5uySHkvxzkp/smt4I7K2qR7t/a6BL0hwrcU59H/Dmqvpp4G3AB7r1lwCXJPl8koNJtk2tQklaodZOu4BhSZ4K/Czw8SSnVz+5+70W2AJcAWwAbkvygqr61nLXKUkr1YoKdQafHL5VVS+ep+0YcHtVfQ94MMn9DEL+juUsUJJWshU1/VJV32YQ2L8GkIEXdc2fZnCWTpJ1DKZjHphGnZK0Uk37lsabgC8CP5HkWJJdwOuAXUnuAo4AO7vuB4BHktwD3Aq8vaoemUbdkrRSTfWWRklSv1bU9IskaXGmdqF03bp1tWnTpmltXpLOSYcOHfpGVa0f1T61UN+0aROzs7PT2rwknZOS/NtC7U6/SFJDxob6pA/dSvIzSU4leU1/5UmSzsQkZ+o3AAt+JT/JGuA64LM91CRJOktjQ32+h27N483AJwEfsiVJU7ToOfUkFwGvBj44Qd/dSWaTzJ48eXKxm5YkzdHHhdI/Bn63qr4/rmNV7auqmaqaWb9+5B05kqSz1MctjTPAzd1TFdcBO5KcqqpP9/DekqQzsOhQr6rNp18nuQH4awNdkqZjbKh3D926AliX5BjwLuA8gKr60JJWJ0k6I1N7oNdMUrMAPlBMkiaW5FBVzYxq9xulktQQQ12SGmKoS1JDDHVJaoihLkkNMdQlqSGGuiQ1xFCXpIYY6pLUEENdkhpiqEtSQwx1SWqIoS5JDTHUJakhhrokNcRQl6SGGOqS1BBDXZIaYqhLUkMMdUlqiKEuSQ0ZG+pJrk9yIsndI9pfl+Rwki8n+UKSF/VfpiRpEpOcqd8AbFug/UHgFVX1AuA9wL4e6pIknYW14zpU1W1JNi3Q/oWhxYPAhsWXJUk6G33Pqe8CPjOqMcnuJLNJZk/2vGFJ0gRn6pNK8vMMQv1lo/pU1T666ZmZpPratiRpoJdQT/JC4M+A7VX1SB/vKUk6c4uefklyMfAp4Deq6v7FlyRJOltjz9ST3ARcAaxLcgx4F3AeQFV9CPh94JnAB5IAnKqqmaUqWJI0WqqmM7U9k9Ts6YUp1SBJ55okhxY6cfYbpZLUEENdkhpiqEtSQwx1SWqIoS5JDTHUJakhhrokNcRQl6SGGOqS1BBDXZIaYqhLUkMMdUlqiKEuSQ0x1CWpIYa6JDXEUJekhhjqktQQQ12SGmKoS1JDDHVJaoihLkkNGRvqSa5PciLJ3SPak+T9SY4mOZzk0v7LlCRNYpIz9RuAbQu0bwe2dD+7gQ8uvixJ0tkYG+pVdRvwzQW67ARurIGDwNOTXNhXgZKkyfUxp34R8NDQ8rFunSRpmS3rhdIku5PMJpk9uZwblqRVoo9QPw5sHFre0K37IVW1r6pmqmpmfQ8bliT9oD5CfT/w+u4umMuBx6rq4R7eV5J0htaO65DkJuAKYF2SY8C7gPMAqupDwN8CO4CjwHeA31qqYiVJCxsb6lV19Zj2At7UW0WSpLPmN0olqSGGuiQ1xFCXpIYY6pLUEENdkhpiqEtSQwx1SWqIoS5JDTHUJakhhrokNcRQl6SGGOqS1BBDXZIaYqhLUkMMdUlqiKEuSQ0x1CWpIYa6JDXEUJekhhjqktQQQ12SGmKoS1JDJgr1JNuS3JfkaJI987RfnOTWJF9KcjjJjv5LlSSNMzbUk6wB9gLbga3A1Um2zun2e8AtVfUS4CrgA30XKkkab5Iz9cuAo1X1QFU9DtwM7JzTp4Af7V4/DfiP/kqUJE1q7QR9LgIeGlo+Brx0Tp93A59N8mbgKcCr5nujJLuB3QAXn2mlkqSx+rpQejVwQ1VtAHYAH03yQ+9dVfuqaqaqZtb3tGFJ0hMmCfXjwMah5Q3dumG7gFsAquqLwI8A6/ooUJI0uUlC/Q5gS5LNSc5ncCF0/5w+/w68EiDJTzEI9ZN9FipJGm9sqFfVKeAa4ABwL4O7XI4kuTbJlV23twJvTHIXcBPwm1VVS1W0JGl+mVb2ziQ1e3rB/JekiSQ5VFUzo9r9RqkkNcRQl6SGGOqS1BBDXZIaYqhLUkMMdUlqiKEuSQ0x1CWpIYa6JDXEUJekhhjqktQQQ12SGmKoS1JDDHVJaoihLkkNMdQlqSGGuiQ1xFCXpIYY6pLUEENdkhpiqEtSQyYK9STbktyX5GiSPSP6vDbJPUmOJPlYv2VKkiaxdlyHJGuAvcAvAseAO5Lsr6p7hvpsAd4B/FxVPZrkWUtVsCRptEnO1C8DjlbVA1X1OHAzsHNOnzcCe6vqUYCqOtFvmZKkSUwS6hcBDw0tH+vWDbsEuCTJ55McTLJtvjdKsjvJbJLZk2dXryRpAWOnX87gfbYAVwAbgNuSvKCqvjXcqar2AfsAZpLqaduSpM4kZ+rHgY1Dyxu6dcOOAfur6ntV9SBwP4OQlyQto0lC/Q5gS5LNSc4HrgL2z+nzaQZn6SRZx2A65oEe65QkTWBsqFfVKeAa4ABwL3BLVR1Jcm2SK7tuB4BHktwD3Aq8vaoeWaqiJUnzS9V0prZnkpo9vTClGiTpXJPkUFXNjGr3G6WS1BBDXZIaYqhLUkMMdUlqiKEuSQ0x1CWpIYa6JDXEUJekhhjqktQQQ12SGmKoS1JDDHVJaoihLkkNMdQlqSGGuiQ1xFCXpIYY6pLUEENdkhpiqEtSQwx1SWqIoS5JDZko1JNsS3JfkqNJ9izQ71eTVJKR/9O1JGnpjA31JGuAvcB2YCtwdZKt8/S7AHgLcHvfRUqSJjPJmfplwNGqeqCqHgduBnbO0+89wHXA//RYnyTpDEwS6hcBDw0tH+vW/b8klwIbq+pvFnqjJLuTzCaZPXnGpUqSxln0hdIkTwLeB7x1XN+q2ldVM1U1s36xG5Yk/ZBJQv04sHFoeUO37rQLgOcD/5Tka8DlwH4vlkrS8psk1O8AtiTZnOR84Cpg/+nGqnqsqtZV1aaq2gQcBK6sqtklqViSNNLYUK+qU8A1wAHgXuCWqjqS5NokVy51gZKkyaWqprLhmeSJU/kp1SBJ55okh6pq5PS23yiVpIYY6pLUEENdkhpiqEtSQ1ZGqCfTrkCSmrAyQl2S1AtDXZIaYqhLUkMMdUlqiKEuSQ0x1CWpIYa6JDXEUJekhhjqktQQQ12SGmKoS1JDDHVJaoihLkkNMdQlqSGGuiQ1xFCXpIZMFOpJtiW5L8nRJHvmaf+dJPckOZzkc0me03+pkqRxxoZ6kjXAXmA7sBW4OsnWOd2+BMxU1QuBTwDv7btQSdJ4k5ypXwYcraoHqupx4GZg53CHqrq1qr7TLR4ENvRbpiRpEpOE+kXAQ0PLx7p1o+wCPrOYoiRJZ2dtn2+W5NeBGeAVI9p3A7sBLu5zw5IkYLIz9ePAxqHlDd26H5DkVcA7gSur6rvzvVFV7auqmaqaWX821UqSFjRJqN8BbEmyOcn5wFXA/uEOSV4C/AmDQD/Rf5mSpEmMDfWqOgVcAxwA7gVuqaojSa5NcmXX7Q+ApwIfT3Jnkv0j3k6StIRSVVPZ8ExSs8MrplSHJJ1LkhyqqplR7X6jVJIaYqhLUkMMdUlqiKEuSQ0x1CWpIYa6JDXEUJekhhjqktQQQ12SGrJyQj2ZdgWSdM5bOaEuSVo0Q12SGmKoS1JDDHVJaoihLkkNMdQlqSErK9QTb22UpEVYWaF+msEuSWdlZYa6JOmsGOqS1BBDXZIasnJD3Xl1STpjE4V6km1J7ktyNMmeedqfnOQvuvbbk2zqu1BJ0nhjQz3JGmAvsB3YClydZOucbruAR6vqx4E/Aq7rpTpvcZSkMzLJmfplwNGqeqCqHgduBnbO6bMT+Ej3+hPAK5Me09hgl6SJrJ2gz0XAQ0PLx4CXjupTVaeSPAY8E/jGcKcku4Hd3eJ3A3dPXGm7wb6OOeO0CjkGjsFpjsP4MXjOQv94klDvTVXtA/YBJJmtqpnl3P5K5Dg4BuAYnOY4LH4MJpl+OQ5sHFre0K2bt0+StcDTgEfOtihJ0tmZJNTvALYk2ZzkfOAqYP+cPvuBN3SvXwP8Y1VVf2VKkiYxdvqlmyO/BjgArAGur6ojSa4FZqtqP/Bh4KNJjgLfZBD84+xbRN0tcRwcA3AMTnMcFjkG8YRaktqxcr9RKkk6Y4a6JDVkKqE+7rEDrUrytSRfTnJnktlu3TOS/H2Sr3S/f2zadfYtyfVJTiS5e2jdvPudgfd3x8bhJJdOr/L+jBiDdyc53h0PdybZMdT2jm4M7kvyy9Opul9JNia5Nck9SY4keUu3ftUcCwuMQX/HQlUt6w+Di61fBZ4LnA/cBWxd7jqm8QN8DVg3Z917gT3d6z3AddOucwn2++XApcDd4/Yb2AF8BghwOXD7tOtfwjF4N/C2efpu7f4ungxs7v5e1kx7H3oYgwuBS7vXFwD3d/u6ao6FBcagt2NhGmfqkzx2YDUZfsTCR4BfmWItS6KqbmNwV9SwUfu9E7ixBg4CT09y4fJUunRGjMEoO4Gbq+q7VfUgcJTB3805raoerqp/7V7/F3Avg2+jr5pjYYExGOWMj4VphPp8jx1YaKdaUsBnkxzqHpkA8Oyqerh7/Z/As6dT2rIbtd+r7fi4pptauH5o6q35Meie5PoS4HZW6bEwZwygp2PBC6XL62VVdSmDJ16+KcnLhxtr8Hlr1d1julr3G/gg8DzgxcDDwB9Ot5zlkeSpwCeB366qbw+3rZZjYZ4x6O1YmEaoT/LYgSZV1fHu9wngLxl8jPr66Y+U3e8T06twWY3a71VzfFTV16vqf6vq+8Cf8sTH6mbHIMl5DMLsz6vqU93qVXUszDcGfR4L0wj1SR470JwkT0lywenXwC8xeErl8CMW3gD81XQqXHaj9ns/8PruzofLgceGPpo3Zc788Kt54qml+4GrMvjPZzYDW4B/We76+tY9jvvDwL1V9b6hplVzLIwag16PhSldAd7B4KrvV4F3TvuK9DLt83MZXMW+Czhyer8ZPKL4c8BXgH8AnjHtWpdg329i8JHyewzmBHeN2m8Gdzrs7Y6NLwMz065/Ccfgo90+Hu7+eC8c6v/ObgzuA7ZPu/6exuBlDKZWDgN3dj87VtOxsMAY9HYs+JgASWqIF0olqSGGuiQ1xFCXpIYY6pLUEENdkhpiqEtSQwx1SWrI/wGHWYJ42h2C5AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "hist, bins = np.histogram(test_image_1.flatten(), 256, [0, 256])\n",
        "plt.hist(test_image_1.flatten(), 256, [0, 256], color='r')\n",
        "plt.xlim([0, 256])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSN-5K3jQrgA"
      },
      "outputs": [],
      "source": [
        "def histogram_equalization_and_CLAHE(img_in):\n",
        "    b,g,r = cv2.split(img_in) \n",
        "    equ_b = cv2.equalizeHist(b)\n",
        "    equ_g = cv2.equalizeHist(g)\n",
        "    equ_r = cv2.equalizeHist(r)\n",
        "    he_final = cv2.merge((equ_b, equ_g, equ_r))\n",
        "    \n",
        "    clahe = cv2.createCLAHE(clipLimit=40)\n",
        "    clahe_b = clahe.apply(equ_b)\n",
        "    clahe_g = clahe.apply(equ_g)\n",
        "    clahe_r = clahe.apply(equ_r)\n",
        "    clahe_final = cv2.merge((clahe_b, clahe_g, clahe_r))\n",
        "    \n",
        "    cv2.imwrite('histogram_equalization.jpeg', he_final)\n",
        "    cv2.imwrite('clahe.jpeg', clahe_final)\n",
        "    return he_final, clahe_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "LyIyXWZbQrgA",
        "outputId": "7dd4e487-891a-4e7e-845e-3e82a18fdcb1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "he_final, clahe_final = histogram_equalization_and_CLAHE(test_image_1)\n",
        "hist, bins = np.histogram(he_final.flatten(), 256, [0, 256])\n",
        "plt.hist(he_final.flatten(), 256, [0, 256], color='r')\n",
        "plt.xlim([0, 256])\n",
        "plt.show()\n",
        "hist, bins = np.histogram(clahe_final.flatten(), 256, [0, 256])\n",
        "plt.hist(clahe_final.flatten(), 256, [0, 256], color='r')\n",
        "plt.xlim([0, 256])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm9bZj30QrgA"
      },
      "outputs": [],
      "source": [
        "gray_img = cv2.cvtColor(test_image_1, cv2.COLOR_BGR2GRAY)\n",
        "hist = cv2.calcHist(gray_img, [0], None, [256], [0, 256])\n",
        "plt.subplot(121)\n",
        "plt.title(\"Image1\")\n",
        "plt.xlabel('bins')\n",
        "plt.ylabel(\"No of pixels\")\n",
        "plt.plot(hist)\n",
        "plt.show()\n",
        "gray_img_eqhist = cv2.equalizeHist(gray_img)\n",
        "hist = cv2.calcHist(gray_img_eqhist, [0], None, [256], [0, 256])\n",
        "plt.subplot(121)\n",
        "plt.title(\"Image2\")\n",
        "plt.xlabel('bins')\n",
        "plt.ylabel(\"No of pixels\")\n",
        "plt.plot(hist)\n",
        "plt.show()\n",
        "gray_img_eqhist = cv2.cvtColor(gray_img_eqhist, cv2.COLOR_GRAY2BGR)\n",
        "cv2.imwrite('/content/gray_img_eqhist.jpeg', gray_img_eqhist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUwlZoMEQrgB"
      },
      "source": [
        "Using CLAHE (Contrast Limited Adaptive Histogram Equalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ0DcaTaQrgB"
      },
      "outputs": [],
      "source": [
        "gray_img_eqhist = cv2.equalizeHist(gray_img)\n",
        "clahe = cv2.createCLAHE(clipLimit=40)\n",
        "gray_img_clahe = clahe.apply(gray_img_eqhist)\n",
        "gray_img_clahe = cv2.cvtColor(gray_img_clahe, cv2.COLOR_GRAY2BGR)\n",
        "cv2.imwrite('/content/gray_img_clahe.jpeg', gray_img_clahe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRFhjfvTQrgB"
      },
      "source": [
        "OTSU Binarization "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7w_GZWeQrgC"
      },
      "outputs": [],
      "source": [
        "ret, thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "# thresh = Image.fromarray(thresh)\n",
        "# thresh.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpZktZe9QrgC"
      },
      "source": [
        "Adaptive Thresholding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpqaXD_wQrgC"
      },
      "outputs": [],
      "source": [
        "thresh1 = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 31, 3)\n",
        "thresh2 = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 13, 5)\n",
        "final = np.concatenate((thresh1, thresh2), axis = 1)\n",
        "# final = Image.fromarray(final)\n",
        "# final.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw5fzHQDQrgC"
      },
      "source": [
        "Test-Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ug41rOkNQrgC"
      },
      "outputs": [],
      "source": [
        "original_image = np.asarray(original_image, dtype=np.float64)\n",
        "print(original_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H84zgxSIQrgD"
      },
      "source": [
        "Simple Pixel Enhancement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gCjVm84QrgD"
      },
      "outputs": [],
      "source": [
        "print(stack_bright.shape)\n",
        "stack_bright = np.asarray(stack_bright, dtype=np.float64)\n",
        "print(\"Simple Pixel Enhancement MSE = \", mse(stack_bright, original_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJqeyiZZQrgD"
      },
      "source": [
        "Linear Pixel Transformation Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lARW6_Z-QrgD"
      },
      "outputs": [],
      "source": [
        "print(image_linear_transform.shape)\n",
        "image_linear_transform = np.asarray(image_linear_transform, dtype=np.float64)\n",
        "print(\"Linear Pixel Transformation Method MSE = \", mse(image_linear_transform, original_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzRLdZGDQrgD"
      },
      "source": [
        "Linear Pixel Transformation Method with Gamma Correction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0bRJd_2QrgE"
      },
      "outputs": [],
      "source": [
        "print(gamma_corrected.shape)\n",
        "gamma_corrected = np.asarray(gamma_corrected, dtype=np.float64)\n",
        "print(\"Linear Pixel Transformation Method with Gamma Correction MSE = \", mse(gamma_corrected, original_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwXJThLPQrgE"
      },
      "source": [
        "Histogram Equalization Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAG_tV4aQrgE"
      },
      "outputs": [],
      "source": [
        "gray_img_eqhist = cv2.cvtColor(gray_img_eqhist, cv2.COLOR_GRAY2BGR)\n",
        "print(gray_img_eqhist.shape)\n",
        "gray_img_eqhist = np.asarray(gray_img_eqhist, dtype=np.float64)\n",
        "print(\"Histogram Equalization Method = \", mse(gray_img_eqhist, original_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-12F0R-QrgE"
      },
      "source": [
        "CLAHE Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t50jzw8MQrgE"
      },
      "outputs": [],
      "source": [
        "gray_img_clahe = cv2.cvtColor(gray_img_clahe, cv2.COLOR_GRAY2BGR)\n",
        "print(gray_img_clahe.shape)\n",
        "gray_img_clahe = np.asarray(gray_img_clahe, dtype=np.float64)\n",
        "print(\"CLAHE Method MSE = \", mse(gray_img_clahe, original_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCEi38iRQrgE"
      },
      "source": [
        "Adaptive Thresholding Method - MEAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wJOFPiIQrgF"
      },
      "outputs": [],
      "source": [
        "thresh1 = cv2.cvtColor(thresh1, cv2.COLOR_GRAY2BGR)\n",
        "print(thresh1.shape)\n",
        "thresh1 = np.asarray(thresh1, dtype=np.float64)\n",
        "print(\"Adaptive Thresholding Method - MEAN MSE = \", mse(thresh1, original_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxizx42VQrgF"
      },
      "source": [
        "Adaptive Thresholding Method - GAUSSIAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpD9Sd9PQrgF"
      },
      "outputs": [],
      "source": [
        "thresh2 = cv2.cvtColor(thresh2, cv2.COLOR_GRAY2BGR)\n",
        "print(thresh2.shape)\n",
        "thresh2 = np.asarray(thresh2, dtype=np.float64)\n",
        "print(\"Adaptive Thresholding Method - GAUSSIAN MSE = \", mse(thresh2, original_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m2HkJcNQrgF"
      },
      "source": [
        "OTSU Binarization Method "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkuA8k23QrgF"
      },
      "outputs": [],
      "source": [
        "thresh = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)\n",
        "print(thresh.shape)\n",
        "thresh = np.asarray(thresh, dtype=np.float64)\n",
        "print(\"OTSU Binarization Method  MSE = \", mse(thresh, original_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-oEbm30QrgF"
      },
      "source": [
        "Using Histogram Equalization on Several Images for Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NLnjJuJQrgG"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "total_mse = 0\n",
        "for file_name in os.listdir(store_path):\n",
        "    try:\n",
        "        im_to_enhance = cv2.imread(store_path + '/' + file_name)\n",
        "        im_original = Image.open(path + '/' + file_name[9:])\n",
        "        original = np.asarray(im_original, dtype=np.float64)\n",
        "        gray_img = cv2.cvtColor(im_to_enhance, cv2.COLOR_BGR2GRAY)\n",
        "        start_time = time.time()\n",
        "        result = cv2.equalizeHist(gray_img)\n",
        "        end_time = time.time()\n",
        "        print(end_time - start_time)\n",
        "        result = cv2.cvtColor(result, cv2.COLOR_GRAY2BGR)\n",
        "        result = np.asarray(result, dtype=np.float64)\n",
        "        print(result.shape)\n",
        "        print(original.shape)\n",
        "        current_mse = mse(result, original)\n",
        "        count += 1\n",
        "        print(f\"image - {count} is enhanced and the mse for the image was {current_mse}\")\n",
        "        total_mse += current_mse\n",
        "        result = np.asarray(result, dtype=np.uint8)\n",
        "        im_output = Image.fromarray(result)\n",
        "        im_output.save(enhanced_path + '/enhanced_eq_hist' + file_name[9:])\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    if count >= 10:\n",
        "        break\n",
        "print(\"Mean MSE = \", total_mse / 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaAo2-OIQrgG"
      },
      "source": [
        "Default parameters for Tan-Triggs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02Iqia4HQrgG"
      },
      "outputs": [],
      "source": [
        "rows = gray_img.shape[0]\n",
        "cols = gray_img.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8hRmiH1QrgG"
      },
      "source": [
        "Gamma Correction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1N5Ib-pXQrgG"
      },
      "outputs": [],
      "source": [
        "gamma = 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c2J3nlTQrgG"
      },
      "source": [
        "Difference of Gaussian (DoG) Filterings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAzFOIqGQrgH"
      },
      "outputs": [],
      "source": [
        "sigma_0 = 1\n",
        "sigma_1 = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwhRwTNWQrgH"
      },
      "source": [
        "Contrast Equalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGPzFXcLQrgH"
      },
      "outputs": [],
      "source": [
        "alpha = 0.1\n",
        "tao = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kux40m6zQrgH"
      },
      "source": [
        "Tan - Triggs Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6PLDi2FQrgH"
      },
      "outputs": [],
      "source": [
        "gamma_corrected = gray_img ** gamma\n",
        "kernel_0 = ImageFilter.GaussianBlur(radius=sigma_0)\n",
        "kernel_1 = ImageFilter.GaussianBlur(radius=sigma_1)\n",
        "# kernel_0 = np.ones((3 * sigma_0, 3 * sigma_0))\n",
        "# kernel_1 = np.ones((3 * sigma_1 + 1, 3 * sigma_1 + 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyZlmzbhQrgH"
      },
      "outputs": [],
      "source": [
        "image_0 = Image.fromarray(gamma_corrected).convert('L').filter(kernel_0)\n",
        "image_1 = Image.fromarray(gamma_corrected).convert('L').filter(kernel_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izG6aH4nQrgI"
      },
      "outputs": [],
      "source": [
        "image_0 = np.array(image_0)\n",
        "image_1 = np.array(image_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnvh-yWcQrgI"
      },
      "outputs": [],
      "source": [
        "image = image_0 - image_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwDLw5vPQrgI"
      },
      "outputs": [],
      "source": [
        "image = image / ((np.mean((abs(image.flatten())) ** alpha)) ** (1 / alpha))\n",
        "image = image / (np.mean([np.min(tao * np.ones((1, rows * cols))) ** alpha, np.min(abs(gray_img.flatten().reshape((1, rows * cols)))) ** alpha]) ** (1 / alpha))\n",
        "image = tao * np.tanh(image / tao)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgO6Cpx5QrgI"
      },
      "outputs": [],
      "source": [
        "max_image = np.max(np.max(image))\n",
        "min_image = np.min(np.min(image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXMtJ-d_QrgI"
      },
      "outputs": [],
      "source": [
        "for i in range(image.shape[0]):\n",
        "    for j in range(image.shape[1]):\n",
        "        image[i][j] = math.ceil(((image[i][j] - min_image) / (max_image - min_image)) * 255)\n",
        "image = np.asarray(image, dtype=np.uint8)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
        "display_image = Image.fromarray(image).convert('RGB')\n",
        "display_image.save('/content/tan_triggs_IMG_2838.jpeg')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BM3D De-Noising Technique"
      ],
      "metadata": {
        "id": "WvoCCYu1Z4H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install bm3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0T-uBvyLSHw",
        "outputId": "52a178dc-d368-4602-bb37-6683f0e4f0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bm3d in /usr/local/lib/python3.7/dist-packages (3.0.9)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from bm3d) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bm3d) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from bm3d) (1.7.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python BM3D.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVehaJ_M4mvm",
        "outputId": "3babc2a2-d6b8-423d-f6b3-eee1a216cec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Read\n",
            "The PSNR of basic image is 29.912951045496143 dB.\n",
            "\n",
            "Basic estimate has been saved successfully.\n",
            "\n",
            "The running time of basic estimate is 392.58781695365906 seconds.\n",
            "\n",
            "The PSNR of final image is 29.150656957072517 dB.\n",
            "\n",
            "Final estimate has been saved successfully.\n",
            "\n",
            "The running time of final estimate is 477.4651083946228 seconds.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bm3d\n",
        "from bm3d import bm3d_rgb, BM3DProfile"
      ],
      "metadata": {
        "id": "HopVAr3LZqFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_noisy = cv2.imread('/content/denoised.jpeg') / 255\n",
        "# y = np.array(Image.open('/content/denoised.jpeg')) / 255\n",
        "# denoised_image = bm3d.bm3d(image_noisy, sigma_psd=30/255, stage_arg=bm3d.BM3DStages.HARD_THRESHOLDING)\n",
        "y_est = bm3d_rgb(image_noisy, sigma_psd=30/255)\n",
        "y_est = y_est * 255\n",
        "cv2.imwrite('denoised_new.jpeg', y_est)"
      ],
      "metadata": {
        "id": "fT4aEy2mZ1lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRe8XImXQrgI"
      },
      "source": [
        "Initializing image size for the Model and<br>\n",
        "data arrays for storing the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqBnsfSPQrgJ"
      },
      "outputs": [],
      "source": [
        "im_size = 512\n",
        "images_darkened = []\n",
        "images_normal = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RoYULIZQrgJ"
      },
      "source": [
        "Obtaining the entire dataset for training and testing purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMvS-yGEQrgJ"
      },
      "outputs": [],
      "source": [
        "for file in os.listdir(path):\n",
        "  if file.endswith('jpeg') and 'darkened' not in file:\n",
        "    img_light = cv2.imread(os.path.join(path, file))\n",
        "    img_light = cv2.cvtColor(img_light, cv2.COLOR_BGR2HSV)\n",
        "    img_light = img_light[:, :, 2]\n",
        "    img_light = cv2.resize(img_light, (im_size, im_size))\n",
        "    img_light = img_light / 255\n",
        "    images_normal.append(img_light)\n",
        "    img_dark_2 = cv2.imread(os.path.join(store_path_2,\n",
        "                                         'darkened_' + file))\n",
        "    img_dark_2 = cv2.rotate(img_dark_2,\n",
        "                            rotateCode=cv2.ROTATE_90_CLOCKWISE)\n",
        "    img_dark_2 = cv2.cvtColor(img_dark_2, cv2.COLOR_BGR2HSV)\n",
        "    img_dark_2 = img_dark_2[:, :, 2]\n",
        "    img_dark_2 = cv2.resize(img_dark_2, (im_size, im_size))\n",
        "    img_dark_2 = img_dark_2 / 255\n",
        "    images_darkened.append(img_dark_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thGP0IBfQrgJ"
      },
      "outputs": [],
      "source": [
        "print(len(images_normal))\n",
        "print(len(images_darkened)) \n",
        "print(\"Done with 0.2 darkened images.\\n\")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRhAE1UXQrgJ"
      },
      "outputs": [],
      "source": [
        "for file in os.listdir(path):\n",
        "  if file.endswith('jpeg') and 'darkened' not in file:\n",
        "    img_light = cv2.imread(os.path.join(path, file))\n",
        "    img_light = cv2.cvtColor(img_light, cv2.COLOR_BGR2HSV)\n",
        "    img_light = img_light[:, :, 2]\n",
        "    img_light = cv2.resize(img_light, (im_size, im_size))\n",
        "    img_light = img_light / 255\n",
        "    images_normal.append(img_light)\n",
        "    img_dark_1 = cv2.imread(os.path.join(store_path_1,\n",
        "                                         'darkened_' + file))\n",
        "    img_dark_1 = cv2.rotate(img_dark_1,\n",
        "                            rotateCode=cv2.ROTATE_90_CLOCKWISE)\n",
        "    img_dark_1 = cv2.cvtColor(img_dark_1, cv2.COLOR_BGR2HSV)\n",
        "    img_dark_1 = img_dark_1[:, :, 2]\n",
        "    img_dark_1 = cv2.resize(img_dark_1, (im_size, im_size))\n",
        "    img_dark_1 = img_dark_1 / 255\n",
        "    images_darkened.append(img_dark_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD1ZqJtxQrgK"
      },
      "outputs": [],
      "source": [
        "print(len(images_normal))\n",
        "print(len(images_darkened))\n",
        "print(\"Done with 0.1 darkened images.\\n\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6YoJLNpQrgK"
      },
      "outputs": [],
      "source": [
        "for file in os.listdir(path):\n",
        "  if file.endswith('jpeg') and 'darkened' not in file:\n",
        "    img_light = cv2.imread(os.path.join(path, file))\n",
        "    img_light = cv2.cvtColor(img_light, cv2.COLOR_BGR2HSV)\n",
        "    img_light = img_light[:, :, 2]\n",
        "    img_light = cv2.resize(img_light, (im_size, im_size))\n",
        "    img_light = img_light / 255\n",
        "    images_normal.append(img_light)\n",
        "    img_dark_3 = cv2.imread(os.path.join(store_path_3,\n",
        "                                         'darkened_' + file))\n",
        "    img_dark_3 = cv2.rotate(img_dark_3,\n",
        "                            rotateCode=cv2.ROTATE_90_CLOCKWISE)\n",
        "    img_dark_3 = cv2.cvtColor(img_dark_3, cv2.COLOR_BGR2HSV)\n",
        "    img_dark_3 = img_dark_3[:, :, 2]\n",
        "    img_dark_3 = cv2.resize(img_dark_3, (im_size, im_size))\n",
        "    img_dark_3 = img_dark_3 / 255\n",
        "    images_darkened.append(img_dark_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLq3agQ8QrgK"
      },
      "outputs": [],
      "source": [
        "print(len(images_normal))\n",
        "print(len(images_darkened))\n",
        "print(\"Done with 0.3 darkened images.\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mzkx4o_IQrgK"
      },
      "source": [
        "Normalization and Storage of Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMfsBexIQrgK"
      },
      "outputs": [],
      "source": [
        "images_darkened = np.array(images_darkened)\n",
        "images_darkened = images_darkened.reshape(-1, im_size, im_size, 1)\n",
        "images_normal = np.array(images_normal)\n",
        "images_normal = images_normal.reshape(-1, im_size, im_size, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbj4ja57QrgK"
      },
      "outputs": [],
      "source": [
        "x_train = images_darkened\n",
        "y_train = images_normal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4A-7iKiQrgL"
      },
      "source": [
        "Commented out IPython magic to ensure Python compatibility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIi-M4GyQrgL"
      },
      "source": [
        "Tensorboard Callbacks to monitor the progress of training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VpqGPWsQrgL"
      },
      "outputs": [],
      "source": [
        "log_dir_1 = \"logs/fit/\" + datetime.datetime.now().strftime(\n",
        "    \"%Y%m%d-%H%M%S\")\n",
        "log_folder = 'log_dir'\n",
        "TensorBoard_callbacks = [tf.keras.callbacks.TensorBoard(\n",
        "                        log_dir=log_folder,\n",
        "                        histogram_freq=1,\n",
        "                        write_graph=True,\n",
        "                        write_images=True,\n",
        "                        update_freq='epoch',\n",
        "                        profile_batch=2,\n",
        "                        embeddings_freq=1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mc7HLbYQrgL"
      },
      "source": [
        "The Auto - Encoder Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaYIm0BhQrgL"
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape=(None, None, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U23nbta2QrgL"
      },
      "source": [
        "Encoder of Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlvhjuCwQrgM"
      },
      "outputs": [],
      "source": [
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwu2xqvxQrgM"
      },
      "outputs": [],
      "source": [
        "x = MaxPooling2D((2, 2), padding='same')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRfZhyzJQrgM"
      },
      "outputs": [],
      "source": [
        "x = Dropout(0.5)(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A21qeFHjQrgM"
      },
      "source": [
        "Decoder of Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ax5KtS5WQrgM"
      },
      "outputs": [],
      "source": [
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gSNbFl3QrgN"
      },
      "outputs": [],
      "source": [
        "x = UpSampling2D((2, 2))(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8VKr7zlQrgN"
      },
      "outputs": [],
      "source": [
        "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azKbBWP9QrgN"
      },
      "source": [
        "Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm-LM4GMQrgN"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=[input_layer], outputs=[output_layer],\n",
        "              name='model_image_enhancer')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0355NhtWQrgN"
      },
      "outputs": [],
      "source": [
        "def PSNR(y_true, y_pred):\n",
        "    return tf.convert_to_tensor(20 * tf.experimental.numpy.log10(tf.reduce_max(tf.reduce_max(y_pred)) / tf.math.sqrt(tf.math.reduce_mean(tf.keras.metrics.mean_squared_error(y_true, y_pred)))))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def SSIM(y_true, y_pred):\n",
        "        return tf.image.ssim(y_true, y_pred, 1.0)"
      ],
      "metadata": {
        "id": "xswb2qoJncTt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAtkn82HQrgN"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam' , loss='mean_squared_error',\n",
        "              metrics=['mae', PSNR, SSIM], run_eagerly=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9zD5TFQQrgO"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train, y_train, validation_split=0.2,\n",
        "                    epochs=50, batch_size=16,\n",
        "                    callbacks=TensorBoard_callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLgmjvZqQrgO"
      },
      "outputs": [],
      "source": [
        "model.save('model_image_enhancer.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH5dda_AQrgO"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('/content/LTSITD_model_0.h5',\n",
        "                                   compile=True,\n",
        "                                   custom_objects={'PSNR':PSNR})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "YYTLHuFkvWYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN-7lCoaQrgO"
      },
      "source": [
        "Dimensions of the Image for Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZQJgSDqQrgO"
      },
      "outputs": [],
      "source": [
        "im_size = 256\n",
        "original_image_1 = cv2.imread('/content/00001_00_10s.jpeg')\n",
        "original_image_2 = cv2.imread('/content/00002_00_10s.jpeg')\n",
        "original_image_3 = cv2.imread('/content/00012_00_10s.jpeg')\n",
        "original_image_4 = cv2.imread('/content/00028_00_10s.jpeg')\n",
        "test_image_1 = cv2.imread('/content/00001_07_0.1s.jpeg')\n",
        "test_image_2 = cv2.imread('/content/00002_08_0.1s.jpeg')\n",
        "test_image_3 = cv2.imread('/content/00012_07_0.1s.jpeg')\n",
        "test_image_4 = cv2.imread('/content/00028_08_0.1s.jpeg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZmPqTOLQrgR"
      },
      "source": [
        "Testing and Viewing the Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5fA4lRCQrgR"
      },
      "outputs": [],
      "source": [
        "# img = cv2.cvtColor(test_image_1, cv2.COLOR_BGR2HSV)\n",
        "# img = img[:, :, 2]\n",
        "img = cv2.resize(test_image_1, (im_size, im_size))\n",
        "img = img / 255.0\n",
        "img = img.reshape(-1, img.shape[0], img.shape[1], 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vucvgsOSQrgS"
      },
      "outputs": [],
      "source": [
        "# or_img = cv2.cvtColor(original_image_1, cv2.COLOR_BGR2HSV)\n",
        "# or_img = or_img[:, :, 2]\n",
        "or_img = cv2.resize(original_image_1, (im_size, im_size))\n",
        "or_img = or_img / 255.0\n",
        "or_img = or_img.reshape(-1, or_img.shape[0], or_img.shape[1], 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMZi4BgCQrgS",
        "outputId": "09d7ee26-08d0-4fc7-97bf-c6f61d8b93d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0948 - mae: 0.2767 - PSNR: 10.2305 - SSIM: 0.1846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09483098983764648,\n",
              " 0.27667832374572754,\n",
              " 10.230496406555176,\n",
              " 0.18463654816150665]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "model.evaluate(img, or_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8kjbL3NQrgS",
        "outputId": "39e0e635-3506-4f60-86d5-7a1a5e76d695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 441ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "pred = model.predict(img)\n",
        "pred = pred * 255\n",
        "pred = np.asarray(pred, dtype=np.uint8)\n",
        "pred = pred[0]\n",
        "# .reshape((im_size, im_size))\n",
        "# dup_img = test_image_1\n",
        "# dup_img = cv2.cvtColor(dup_img, cv2.COLOR_BGR2HSV)\n",
        "# dup_img = cv2.resize(dup_img, (im_size, im_size))\n",
        "# dup_img[:, :, 2] = pred\n",
        "# dup_img = cv2.cvtColor(dup_img, cv2.COLOR_HSV2BGR)\n",
        "cv2.imwrite('/content/predicted_image.jpeg', pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKbWU-72QrgS",
        "outputId": "113edc75-7a26-4345-98e6-eba9ebbbf2dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "dark_img = cv2.resize(test_image_1, (im_size, im_size))\n",
        "cv2.imwrite('/content/dark_img.jpeg', dark_img)\n",
        "light_img = cv2.resize(original_image_1, (im_size, im_size))\n",
        "cv2.imwrite('/content/light_img.jpeg', light_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Making a Comparison of Metrics like PSNR, SSIM, MSE and MAE for the Different Techniques Implemented"
      ],
      "metadata": {
        "id": "Y6PwiHuk4lyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "im_size = 512\n",
        "pred_img = cv2.imread('/content/predicted_image_210_140.jpeg').astype('float')\n",
        "orig_im = cv2.imread('/content/orig_image_210.jpeg').astype('float')\n",
        "pred_img = cv2.resize(pred_img, (im_size, im_size))\n",
        "orig_im = cv2.resize(orig_im, (im_size, im_size))\n",
        "print(\"MSE = \", tf.math.sqrt(tf.math.reduce_mean(tf.keras.metrics.mean_squared_error(orig_im, pred_img))).numpy())\n",
        "print(\"MAE = \", tf.math.sqrt(tf.math.reduce_mean(tf.keras.metrics.mean_absolute_error(orig_im, pred_img))).numpy())\n",
        "print(\"PSNR = \", PSNR(orig_im, pred_img).numpy())\n",
        "print(\"SSIM = \", SSIM(orig_im, pred_img).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjWxuLG0tlZd",
        "outputId": "68f07c2f-1d45-414c-987c-188d171b6f80"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE =  10.030948622504953\n",
            "MAE =  2.692806947969572\n",
            "PSNR =  28.103963488573353\n",
            "SSIM =  0.55256015\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}