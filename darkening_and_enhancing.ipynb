{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "947de470"
      },
      "outputs": [],
      "source": [
        "# Importing all the necessary modules\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, UpSampling2D, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "import imutils\n",
        "# from guidedfilter import guided_filter"
      ],
      "id": "947de470"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "082c8e72"
      },
      "outputs": [],
      "source": [
        "# Paths to various folders and files\n",
        "\n",
        "path = '/Users/rohitramesh4547gmail.com/Desktop/IITG/Semester-7/BTP/Good_Illumination_Images'\n",
        "store_path = '/Users/rohitramesh4547gmail.com/Desktop/IITG/Semester-7/BTP/Darkened_Images_0.2'\n",
        "fold_path = '/Users/rohitramesh4547gmail.com/Desktop/IITG/Semester-7/BTP'\n",
        "enhanced_path = '/Users/rohitramesh4547gmail.com/Desktop/IITG/Semester-7/BTP/Enhanced_Images_Histogram_Equalization'\n",
        "test_path = fold_path + '/test_dark.jpeg'\n",
        "path = '/content/drive/MyDrive/Illumination_Enhancement_BTP/Good_Illumination_Images'\n",
        "store_path_1 = '/content/drive/MyDrive/Illumination_Enhancement_BTP/Darkened_Images_0.1'\n",
        "store_path_2 = '/content/drive/MyDrive/Illumination_Enhancement_BTP/Darkened_Images_0.2'\n",
        "store_path_3 = '/content/drive/MyDrive/Illumination_Enhancement_BTP/Darkened_Images_0.3'\n",
        "rain_path = '/content/drive/MyDrive/Illumination_Enhancement_BTP/Rain_Images'\n",
        "snow_path = '/content/drive/MyDrive/Illumination_Enhancement_BTP/Snow_Images'"
      ],
      "id": "082c8e72"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZhk1fu5a8iS",
        "outputId": "5d9c2e37-a5fe-424d-f357-7707b76da602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# For Google Colab Only!\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "GZhk1fu5a8iS"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d368e3cb"
      },
      "outputs": [],
      "source": [
        "# Loading Image for testing and converting it to gray-scale for the Medium Article Methods\n",
        "test_image = cv2.imread(store_path_1 + '/darkened_IMG_2821.jpeg')\n",
        "gray_img = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "original_image = cv2.imread(path + '/IMG_2821.jpeg')"
      ],
      "id": "d368e3cb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58a107e5"
      },
      "outputs": [],
      "source": [
        "# Saved in Darkened_Images_0.1\n",
        "\n",
        "for file_name in os.listdir(path):\n",
        "    try:\n",
        "        img = Image.open(path + '/' + file_name)\n",
        "        enhancer = ImageEnhance.Brightness(img)\n",
        "\n",
        "        factor = 0.1\n",
        "        im_output = enhancer.enhance(factor)\n",
        "        im_output.save(store_path_1 + '/darkened_' + file_name)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "id": "58a107e5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeJ2j_FSi4Xk"
      },
      "outputs": [],
      "source": [
        "# Function defined to Calculate Mean Squared Error \n",
        "\n",
        "def mse(result, truth):\n",
        "    sum_of_squares = 0\n",
        "    for i in range(truth.shape[0]):\n",
        "        for j in range(truth.shape[1]):\n",
        "            for k in range(truth.shape[2]):\n",
        "                sum_of_squares += pow(truth[i][j][k] - result[i][j][k], 2)\n",
        "    return (sum_of_squares / (truth.shape[0] * truth.shape[1] * truth.shape[2]))"
      ],
      "id": "NeJ2j_FSi4Xk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6528e698"
      },
      "outputs": [],
      "source": [
        "def get_illumination_channel(I, w):\n",
        "    M, N, _ = I.shape\n",
        "    padded = np.pad(I, ((int(w/2), int(w/2)), (int(w/2), int(w/2)), (0, 0)), 'edge')\n",
        "    darkch = np.zeros((M, N))\n",
        "    brightch = np.zeros((M, N))\n",
        "    for i, j in np.ndindex(darkch.shape):\n",
        "        darkch[i, j] = np.min(padded[i:i + w, j:j + w, :]) # dark channel\n",
        "        brightch[i, j] = np.max(padded[i:i + w, j:j + w, :]) # bright channel\n",
        "    return darkch, brightch"
      ],
      "id": "6528e698"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3618b3b9"
      },
      "outputs": [],
      "source": [
        "darkch, brightch = get_illumination_channel(test_image, 5)\n",
        "# darkch = Image.fromarray(darkch)\n",
        "# brightch = Image.fromarray(brightch)\n",
        "# brightch.show()"
      ],
      "id": "3618b3b9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c468896"
      },
      "outputs": [],
      "source": [
        "def get_atmosphere(I, brightch, p=0.1):\n",
        "    M, N = brightch.shape\n",
        "    flatI = I.reshape(M*N, 3) # reshaping image array\n",
        "    flatbright = brightch.ravel() #flattening image array\n",
        "    searchidx = (-flatbright).argsort()[:int(M*N*p)] # sorting and slicing\n",
        "    A = np.mean(flatI.take(searchidx, axis=0), dtype=np.float64, axis=0)\n",
        "    return A"
      ],
      "id": "3c468896"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "344c2b36"
      },
      "outputs": [],
      "source": [
        "A = get_atmosphere(test_image, brightch)"
      ],
      "id": "344c2b36"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcf50720"
      },
      "outputs": [],
      "source": [
        "def get_initial_transmission(A, brightch):\n",
        "    A_c = np.max(A)\n",
        "    init_t = (brightch-A_c)/(1.-A_c) # finding initial transmission map\n",
        "    return (init_t - np.min(init_t))/(np.max(init_t) - np.min(init_t)) # normalized initial transmission map"
      ],
      "id": "fcf50720"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c15ad20"
      },
      "outputs": [],
      "source": [
        "init_map = get_initial_transmission(A, brightch)"
      ],
      "id": "7c15ad20"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23b7f3ea"
      },
      "outputs": [],
      "source": [
        "def get_corrected_transmission(I, A, darkch, brightch, init_t, alpha, omega, w):\n",
        "    im = np.empty(I.shape, I.dtype);\n",
        "    for ind in range(0, 3):\n",
        "        im[:, :, ind] = I[:, :, ind] / A[ind] #divide pixel values by atmospheric light\n",
        "    dark_c, _ = get_illumination_channel(im, w) # dark channel transmission map\n",
        "    dark_t = 1 - omega*dark_c # corrected dark transmission map\n",
        "    corrected_t = init_t # initializing corrected transmission map with initial transmission map\n",
        "    diffch = brightch - darkch # difference between transmission maps\n",
        "    for i in range(diffch.shape[0]):\n",
        "        for j in range(diffch.shape[1]):\n",
        "            if(diffch[i, j] < alpha):\n",
        "                corrected_t[i, j] = dark_t[i, j] * init_t[i, j]\n",
        "    return np.abs(corrected_t)"
      ],
      "id": "23b7f3ea"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4810e69d"
      },
      "outputs": [],
      "source": [
        "corrected_map = get_corrected_transmission(test_image, A, darkch, brightch, init_map, 0.4, 0.75, 5)\n",
        "# corrected_map = Image.fromarray(corrected_map)\n",
        "# corrected_map.show()"
      ],
      "id": "4810e69d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3e722d8"
      },
      "outputs": [],
      "source": [
        "def get_final_image(I, A, refined_t, tmin):\n",
        "    refined_t_broadcasted = np.broadcast_to(refined_t[:, :, None], (refined_t.shape[0], refined_t.shape[1], 3)) # duplicating the channel of 2D refined map to 3 channels\n",
        "    J = (I-A) / (np.where(refined_t_broadcasted < tmin, tmin, refined_t_broadcasted)) + A # finding result \n",
        "\n",
        "    return (J - np.min(J))/(np.max(J) - np.min(J)) # normalized image"
      ],
      "id": "f3e722d8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef7137c3"
      },
      "outputs": [],
      "source": [
        "final = get_final_image(test_image, A, corrected_map, 0.1)\n",
        "final = (final*255).astype(np.uint8)\n",
        "# final_img = Image.fromarray(final)\n",
        "# final_img.show()"
      ],
      "id": "ef7137c3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60791309"
      },
      "outputs": [],
      "source": [
        "def reduce_init_t(init_t):\n",
        "    init_t = (init_t*255).astype(np.uint8) \n",
        "    xp = [0, 32, 255]\n",
        "    fp = [0, 32, 48]\n",
        "    x = np.arange(256) # creating array [0,...,255]\n",
        "    table = np.interp(x, xp, fp).astype('uint8') # interpreting fp according to xp in range of x\n",
        "    init_t = cv2.LUT(init_t, table) # lookup table\n",
        "    init_t = init_t.astype(np.float64)/255 # normalizing the transmission map\n",
        "    return init_t"
      ],
      "id": "60791309"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81ed77d5"
      },
      "outputs": [],
      "source": [
        "def dehaze(im, tmin=0.1, w=5, alpha=0.4, omega=0.75, p=0.1, eps=1e-3, reduce=False):\n",
        "    I = np.asarray(im, dtype=np.float64) # Convert the input to a float array.\n",
        "    I = I[:, :, :3] / 255\n",
        "    m, n, _ = I.shape\n",
        "    Idark, Ibright = get_illumination_channel(I, w)\n",
        "#     print(\"Obtained bright and dark channel priors\")\n",
        "#     Image.fromarray(Idark).save(fold_path + '/dark_channel_prior.png')\n",
        "#     Image.fromarray(Ibright).save(fold_path + '/bright_channel_prior.jpg')\n",
        "    A = get_atmosphere(I, Ibright, p)\n",
        "#     print(\"Obtained atmosphere lighting\")\n",
        "#     Image.fromarray(A).save(fold_path + '/atmosphere.jpg')\n",
        "    init_t = get_initial_transmission(A, Ibright) \n",
        "#     print(\"Obtained initial transmission map\")\n",
        "#     Image.fromarray(init_t).save(fold_path + '/init_transmission.jpg')\n",
        "    if reduce:\n",
        "        init_t = reduce_init_t(init_t)\n",
        "#         print(\"Obtained reduced transmission map\")\n",
        "#         Image.fromarray(init_t).save(fold_path + '/reduced_transmission.jpg')\n",
        "    corrected_t = get_corrected_transmission(I, A, Idark, Ibright, init_t, alpha, omega, w)\n",
        "#     print(\"Obtained corrected transmission map\")\n",
        "#     Image.fromarray(corrected_t).save(fold_path + '/corrected_transmission.jpg')\n",
        "\n",
        "    normI = (I - I.min()) / (I.max() - I.min())\n",
        "    refined_t = guided_filter(normI, corrected_t, w, eps) # applying guided filter\n",
        "#     print(\"Obtained image after applying guided filter\")\n",
        "#     Image.fromarray(refined_t).save(fold_path + '/guided_filter.jpg')\n",
        "    \n",
        "    J_refined = get_final_image(I, A, refined_t, tmin)\n",
        "#     print(\"Obtained final image before enhancement\")\n",
        "#     Image.fromarray(J_refined).save(fold_path + '/J_refined_before_enhancement.jpg')\n",
        "    \n",
        "    enhanced = (J_refined * 255).astype(np.uint8)\n",
        "    f_enhanced = cv2.detailEnhance(enhanced, sigma_s=10, sigma_r=0.15)\n",
        "    f_enhanced = cv2.edgePreservingFilter(f_enhanced, flags=1, sigma_s=64, sigma_r=0.2)\n",
        "    return f_enhanced"
      ],
      "id": "81ed77d5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4abd5e1c"
      },
      "outputs": [],
      "source": [
        "# Stack Exchange Solution (Increasing value in HSV image)\n",
        "def increase_brightness(img, value):\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    hsv[:, :, 2] += value\n",
        "    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "    return img\n",
        "\n",
        "stack_bright = increase_brightness(test_image, 50)\n",
        "# stack_bright = Image.fromarray(stack_bright)\n",
        "# stack_bright.show()"
      ],
      "id": "4abd5e1c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13d3300d"
      },
      "outputs": [],
      "source": [
        "# OpenCV method using (alpha * pixel + beta) ^ gamma method\n",
        "def increase_contrast_brightness(img, alpha, beta, gamma):\n",
        "    new_image = np.zeros(img.shape, img.dtype)\n",
        "    for y in range(img.shape[0]):\n",
        "        for x in range(img.shape[1]):\n",
        "            for c in range(img.shape[2]):\n",
        "                new_image[y, x, c] = np.clip(alpha * img[y, x, c] + beta, 0, 255)\n",
        "    lookUpTable = np.empty((1, 256), np.uint8)\n",
        "    for i in range(256):\n",
        "        lookUpTable[0, i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255)\n",
        "    res = cv2.LUT(new_image, lookUpTable)\n",
        "    return new_image, res\n",
        "\n",
        "image_linear_transform, gamma_corrected = increase_contrast_brightness(test_image, 2.2, 50, 0.4)\n",
        "# gamma_corrected = Image.fromarray(gamma_corrected)\n",
        "# gamma_corrected.show()"
      ],
      "id": "13d3300d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "cc116358",
        "outputId": "51205db6-2b57-4983-f7d6-d0a723ff4d1f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM4AAAEWCAYAAAAuBagyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2de5wdVZXvv6u78054BGJEIAQx4qCjgBEVdRgV5eE44IuLjxEZlPEC96Lj515hxgfjncww4jUMnysoDgg4CMP4AoGRN0YQiAmGQBIgISSG0CQhz046SXefs+4fteucOnWq6lRXnzqPYn0/n/M5dXa9diX167X22nuvLaqKYRijo6fdFTCMbsSEYxgZMOEYRgZMOIaRAROOYWTAhGMYGTDhGEYGTDgdioisEZET210PHxF5vYjcKiKbRGSLiNwlIke2u17twoRjpGU/4DbgSGAmsBC4ta01aiMmnA5HRD4nIg+LyHwR2SYiq0XkeFe+TkQ2ishZgeM/JCJ/EJEdbv8loet9VkTWishmEfl60LKJSI+IXCQiz7n9t4jIdABVXaiq16jqFlUdBuYDR4rIAS385+gYTDjdwduBpcABwE+Am4G3Aa8DPgP8PxGZ6o7dBXwWz0J8CPjvInI6gIgcBVwJfBo4CNgXODhwn/8BnA6cALwG2Ap8L6ZOfwa8pKqbm/OIXYaq2qcDP8Aa4ETgc8DKQPmfAgrMDJRtBo6Ouc7lwHy3/Q3gpsC+ycAQcKL7vQJ4f2D/QcAw0Be65iHAeuCT7f53atenL2ddGs1hQ2B7N4CqhsumAojI24FLgTcB44EJwH+6414DrPNPUtVBEQlajMOAX4hIOVBWwmvTrHfXnwHcDVypqjeN+cm6FHPVisdP8Brxh6rqvsD3AXH7+vGsBQAiMgnP/fNZB5yiqvsFPhNV1RfN/niiuU1V57XgWToWE07xmAZsUdU9InIc8KnAvp8CH3bBhfHAJVRFBZ7I5onIYeBZFxE5zW3vA9wFPKyqF7XgOToaE07xOA/4logM4LVpbvF3qOoyvADAzXjWZyewEdjrDvlXPGt1tzv/UbzABMBH8AISZ4vIzsBnVgueqeMQ19gzXoG4SNw2YI6qPt/u+nQTZnFeYYjIh0VksohMAb4DPIkXwTNGgQnnlcdpwIvuMwc4U83tGDXmqhlGBsziGEYGuroD9MADD9TZs2e3uxpGQVm8ePHLqjojal9XC2f27NksWrSo3dUwCoqIrI3bZ66aYWTAhGMYGTDhGEYGTDiGkQETjmFkwIRjGBnITTgiMlFEForIEyKyTET+wZVfJyLPi8gS9znalYuIXCEiq0RkqYgcm1fdDGOs5NmPsxd4n6ruFJFxwEMi8l9u3/9S1Z+Gjj8Fb+zUHLyh7FdRHdI+Kn79VD8vbN3N59/z2oxVN4xkcrM46rHT/RznPkkD404DbnDnPQrsJyIHZbn33cs2cN3v1mQ51TBSkWsbR0R6RWQJ3mSpe1T1MbdrnnPH5ovIBFd2MIH58MAL1GZg8a95rogsEpFFmzZtirlx0x7BMCLJVTiqWlLVo/HmuR8nIm8CLgbegDebcDrw1VFe82pVnauqc2fMiBxG5I7LXm/DaERLomqqug14ADhZVfudO7YX+BFwnDtsPXBo4DQ/BdGoETM5Rs7kGVWbISL7ue1JwAeAp/12i4gIXvK7p9wptwGfddG1dwDbVbU/273HXH3DSCTPqNpBwPUi0osn0FtU9XYRud/l5hJgCfBFd/ydwKnAKmAQOHssN7cJekae5CYcVV0KHBNR/r6Y4xU4vxn3FpLDd4YxVgo5csBcNSNvCikcsKiakS+FFI4gqDlrRo4UUzhiFsfIl8IKxzDypJDCAYuqGflSUOGIuWpGrhRSOOaqGXlTSOF4mMkx8qOQwhEsqmbkSzGFY66akTOFFA6Yo2bkSyGFI4iNjjZypZjCEbM4Rr4UUzjtroBReAopHLCompEvhRSOiLVxjHwppHCCrNo4wLk3LGLvSKndVTEKRGGF49ubi3/+JHcv38AT67a3tT5GsWhH7ujDReQxlyP6P0RkvCuf4H6vcvtnZ783FlYzciVPi+Pnjn4LcDRwskv79C/AfFV9HbAVOMcdfw6w1ZXPd8dlwvKqGXnTjtzR7wP8hOvX4+VWAy939PVu+6fA+13utWz3z3qiYaSgpbmjgeeAbao64g4J5oeu5I52+7cDB0Rcs2HuaG/qtEnHyI+W5o7Gyxk91ms2zB1tjpqRN63OHf1OvOU7/ESIwfzQldzRbv++wOYs97MhN0betDp39Ao8AX3cHXYWcKvbvs39xu2/X8fgb5mnZuRJO3JHLwduFpF/BP4AXOOOvwb4sYisArYAZ2a9sYjlVTPypR25o1dTXdojWL4H+EQz7m1tHCNvijtywAyOkSPFFI4FB4ycKaRwbOSAkTeFFA5gJsfIlUIKx+vHMeUY+VFM4bS7AkbhKaZwbJkPI2cKKRywJo6RL4UUjuVVM/KmmMKxRo6RM4UUDpirZuRLIYVjqxUYeVNI4ZivZuRNMYVjGDlTSOH49sYia0ZeFFM4EZ6aichoJsUUjrM5phUjLwopHJ+gbsaQos0w6iikcHyNmHtm5EWeWW4OFZEHRGS5yx19oSu/RETWi8gS9zk1cM7FLnf0MyJyUuZ7N+MBDCOBPLPcjABfUdXHRWQasFhE7nH75qvqd4IHi8hReJlt3gi8BrhXRF6vqpnX5wjaG7M+RjPJM3d0v6o+7rYH8HKqHZxwymnAzaq6V1WfB1YRkQ0nDVVXLcvZhtGYlrRx3JIdxwCPuaILRGSpiFwrIvu7skruaEcwr/Ro75eqzDCykrtwRGQq8DPgS6q6A7gKOAJv6Y9+4P+O8noNk6772PRpIy/yXq1gHJ5oblTVnwOo6gaXjL0M/JCqO1bJHe0I5pWukCbpevXYJjyEYUSQZ1RN8NLarlDV7wbKDwoc9hHgKbd9G3CmW5ntcGAOsDDbvevLLDhgNJM8o2rvAv4KeNKtkQPwd8AnReRovKDXGuBvAFR1mYjcAizHi8idnzWiZnnVjLzJM3f0Q0R3qdyZcM48YF7z6lDdtuCA0UyKPXIgEBwwV81oJsUUTkSZycZoJoUUjk/QyJjBMZpJIYVTddUMIx+KKZwIZ806Q41mUkjh+NQEBEw3RhMppHCiXDXTjdFMCimcKCw4YDSTQgrH7+w0sRh50VA4InKhiOwjHteIyOMi8sFWVG7M1DRxTEVG80hjcf7aTQf4ILA/3vizS3Ot1Rip5FWrGTnQnroYxSSNcPz38FTgx6q6jA6f1h85Orr11TAKTBrhLBaRu/GEc5fLH1DOt1rNoXbkgEnHaB5pRkefgzdbc7WqDorIAcDZ+VZrbFRdtSomG6OZxApHRI4NFb22W4bmd0s9je4lyeIk5QJQ4H1NrkvTsZEDRl7ECkdV39vKijST6JEDphyjeaTpx5ksIl8Tkavd7zki8hf5Vy07kfNxTDdGE0kTVfsRMAQc736vB/4xtxo1g4iRAyYco5mkEc4RqvptYBhAVQdJ0Y+TkDt6uojcIyIr3ff+rlxE5AqXO3ppRHBi1Jh7ZuRFGuEMicgkXJNBRI4A9qY4z88dfRTwDuB8lx/6IuA+VZ0D3Od+A5yClxJqDnAuXuLCTNjUaSNv0gjnEuDXwKEiciPey/7VRicl5I4+DbjeHXY9cLrbPg24QT0eBfYL5WBLjUR05FgHqNFMGnaAqurdIrIYz2oIcKGqvjyam4RyR89U1X636yVgptuOyx3dT0asA9TIizRRtR8DI6p6h6reDkwRkfvS3iAid3QF9czAqN7pNLmjo5YyNINjNJM0rtpDwGMicqqIfAG4B7g8zcWjckcDG3wXzH1vdOVNyx1tAweMvEnjqv1ARJYBDwAvA8eo6kuNzovLHY2XI/osvKkJZwG3BsovEJGbgbcD2wMuXSbUnDUjJxoKR0T+Cvg68FngzcCdInK2qj7R4NS43NGXAreIyDnAWuAMt+9OvBHYq4BBxjCQtBIbMFfNyIk0o6M/BrxbVTcCN4nIL/CiYUcnnZSQOxrg/RHHK3B+ivo0xObjGHmTxlU7PfR7oYhkWmKwVVSCA4EyszhGM0maVvC/VfXbInJFzCH/M6c6NQ3ruzHyIsnirHDfi1tRkaYS6aqZiIzmkTSt4Ffu+3oAEdnH+6kDLapbZiw4YORNmg7QuSLyJLAUeEpEnhCRt+ZfteZiujGaSZqo2rXAear6WwAReTfeVIM351mxsRCVkNDaO0YzSTNyoOSLBiph5pH8qjR24mLgL27b3dJ6GMUljXB+IyI/EJE/F5ETRORK4EERObYZc2byIGopw4XPb+H4S+/nl3+oG8VjGKMmjav2Fvf9zVD5MXR40o6gd7ai3xtfunjtVk4/5uA21cgoCmk6QLsuaYeNHDDyppirFdjIASNnCikcH4ukGXkRKxwR+YT7Prx11WkO5qoZeZNkcS523z9rRUXyoEYsZn2MJpIUHNjsVik4XERuC+9U1b/Mr1rNoVEG3FUbd7LPpD5eNW1iy+pkFIMk4XwIOBb4Mcl5pDsOiUhz44uorMr5Nz7O2e+azce//wh9PcKqfzq19ZU0upqkQZ5DwKMicryqbnJJN1DVnS2rXUai86p5ytm+e5g7nuznkdWbARgpmwtnjJ40UbWZIvIHYBmwXEQWi8ibcq7XmKiMHDBNGDmRRjhXA3+rqoep6izgK66s47F+HCMv0ghniqo+4P9Q1QeBKbnVqAlIhLNmwjGaSRrhrBaRr4vIbPf5GrC60Ukicq2IbBSRpwJll4jIehFZ4j6nBvZd7BKuPyMiJ2V7HP9a3retK2XkRarl2oEZwM/x+nQOdGWNuA44OaJ8vqoe7T53Arhk7GcCb3TnXCkivSnukUjtcu0mHaN5pBnkuZUMiTlUdYHLGZ2G04CbVXUv8LyIrAKOAx4Z7X0heQ0Sk4/RDNoxVu0Ct/7Ntf7aOMQnXK8jVe7opKiaKcdoAq0WzlXAEXjJDPvJ0LGaJnd09dj67bK5bEYTaKlwVHWDqpZUtQz8EM8dg5QJ19PjTysItHHcdifrZu9IydpiXUKaLDeHiMgvRGSTi5L9TEQOyXKz0EJRHwH8iNttwJkiMsGNxp4DLMxyD+8+9WWdbnF27h3hyK/9mvn3rmx3VYwUpF089zbgIOA1wK9cWSIichNe4/5IEXnBJVn/tog8KSJLgfcCXwZQ1WXALcByvNXfzlfVUobn8e7tvqM00pmygW2DQwD8bPELba6JkYY0OQdmqGpQKNeJyJcanaSqn4wovibh+HnAvBT1yYQvGHOFjGaQxuJsFpHPiEiv+3wG2Jx3xcaCRPhqvmC6STebBtKsUWy0g7QdoGfgrdfZD3ycMaxd0woiU+C673JFQJ2toHuXb+Bt8+7ltyu9kPvazbv44YKGAzaMFpGmA3Qt0PGT1qKoSbReCQ60py6jZfEftwKw9IXtvGfODD71w8dYv203Z7ztUPadNK7NtTOSlvn4RsJ5qqr/J4f6NIWkNUA7QTeL125lzsyp7DMxvQAG9gx7G53wAEaiq7Yr4gNwDvDVnOs1JpIGebbbRds9VOJjV/2Ov7mh+1ZPMaokzQCt9OqLyDTgQry2zc10yVTq2vk4nREcGC6XAXhq/fb2VsQYE4ltHBGZDvwt8Gm8dT+PdYM+O5pKQkLVuuSEndoBmrZatkBWZ5DUxrkM+CjebM8/7YZcAxUCbZzwUJsO1U1qur3+RSGpjfMVvJECXwNeFJEd7jMgIjtaU71s1Oe4qdJuixN3+7T1Mt10BkltnK5Pj1sbHHCWp/K7TcTcOK2e2y18w6PrxRFF9MgB/9vbKLepQyfuxU8rCBNOZ1BM4VS2AsGBUBunXa9fvHDSnW+66QwKKRwf1fooVLnNyokXiFmcbqKQwomej1PbxmnXCxjXAZvW4nTLkKGiU0zhRCws5VNuu6sWV54yquaOGxops2c485QlY4wUUjg+kXnV/OBAYOfC57dw/9MbWlKn2DZOOd35/uknX76AN3z9102qlTFaCimcoKsWDg6UQ98AZ/zgEf76ukUtqVtQNgue3cTsi+5gzcu7Uo8I8IW3+uVdDY408qSYwnHfqlp5ISvzcGhzcCCg2F+4peMf/+PWumhZfEdpXjUzRkMhheMrJ/iOVSxN2f/druBAdLn143QXuQknJnf0dBG5R0RWuu/9XbmIyBUud/RSETm2GXWozatWa3na9QKm7ceJm1PU7mkRhkeeFuc66nNHXwTcp6pzgPvcb4BT8FJCzQHOxUtcmJmo1QrCL2zS63fv8g2s3DAwlirEEiectIIw3XQGuQlHVRcAW0LFp+FNT8B9nx4ov0E9HgX2C+VgGxWViWyBkQPVoEDjeTmfv2ERH5i/IOvtI/ncjxby6X97NLKNomr9ON1GmvRQzWSmqva77ZeAmW47Lnd0PyFE5Fw8q8SsWbOS7xYYOeA3ytv1F/vBZza5+4/N4lgbpzNoW3BAvTdl1G9BmtzRUc2DLG2bW5es55ZF6xofOAqiLIbIaCyOCacTaLXF2SAiB6lqv3PFNrrypuaO9kdHR0XVkt67VRsH+P2a6gTXC29eAsAZcw+NO2XUVMLhIXVbG6e7aLVwbgPOAi5137cGyi8QkZuBtwPbAy5dZoIvWbUfJ56TL/9t7qtQV0YI1ET8zOJ0G3mGo6NyR18KfEBEVgInut8Ad+Itj7gKbxWD88Z27/qy8HycKEYrmt+v2cJwqcyyF7dXcj83opOiap+8+lH+6c4VzbvgK4jcLE5M7miA90ccq8D5zbp3deq0Vl60UqWN05x7LH9xB5/4/iOc8+7Dueah53n9zKnc/eUTGp4X9eKLpG/spbE4ty5Zz5J12/jmh9+YeNwjqzfzyOrN/N2pf5Ly7oZPIUcOBPOqhacRjCVLzLUPPc/jLsPm5l1eXudnXvL6e57dEJ3LZLhUrhlmE/Xie66a1pVFESX8dVsGueyupytW68Kbl/Cjh9ckPosxNgopHB+lPp9a2lHIUXzr9uV89MrfjeqcOX//X3zhhuoA0rHPAK0/8LwbH+d7DzwXK94g//7oWrbuSudWGvEUVDjBydO1NGPIyrMbBli1cae7fuPr3ff0xsp22vk4cUNuos4fGimnqsuK/h187ZdP8eVbltSUbxrYy+yL7uDe5a2ZWlEEWh1VawlVVy3CLcpwvadf2sERM6ZWfn8wMKogaMH6t++mr6eHGdMmxF4rqk4i6Ss2lqiaL7AtIYuzvN/L9nX9I2s48aiZ4dOMCAopHB/PVasty/LinXz5b/nc8bMj95UC13vnP98PwLWfm8uzG3byxROOqDs+fsiN9eN0E4UUTtDLCb9npYxtHD8oECYqzZQ/KS5KOBWLE3LFxtLGMVpPIds4IoEJOaEXrdkdiKO9XkUgDSyhTWTrbAopHB+NaC6PZDQ5cS9yaZQvcvwgz3TH1wvMlNQOCimchHWlMrcRSjF/6kebETTu8LAAotb48c6vLYirV7B+azdbfoJmU0zhBDtAQ+9VKaNy4l7QpBc3yhpEdoCSFKYOXzN+f1Qf1ZUPruKEyx7MbWLeK5ViCieQ2SbsrDX6Cx1HlpzPUfeKHjmgsW2c+pmr8a5blBv32PPeXMIXt++JracxegopHJ9mhaMh3lIlXS8u9Bx1jbqO2sq6PiGhhKxKcHdYqHXWKramxmgppHCCve51rlpWi5PBVYsSVXRZvUDCeeDizi8HUmCFxR2uW9ZnN+oppHB8otsY2a4V36iPPyfqRa0cHxB3OcJV84Xql/sh9vAlg2JpFIGrcetS/kNsHNhjkbsIii0cmueexAYHkto4aS1OWetdsPB3ZbBqyDKVq226cKS9HBJV8BnSBEmWv7iD4+bdx00Lmzt9vAgUUji1rlpzpBPXlklyf0oRnTxRHaBlrRd4XI6EJNetkWsWN70h7tme2+QNZH34uZcj97+SKaZwQvmim0GWfpzhiPhwXIg6LqrWKLiRJIDg7UWkxsoE97VrdbpuppDCqaJNE0+WeTT+aORGx0cFByoWJ3RC+PRSksWJCRZIwnnDpTJrLKF7QwopnLi5LGMhSxtnOMJVi2z3lOsFXnXVasvjom9R164PT7t2EvGW6lu/Ws6ff+dBNg3sraunUaUto6NFZA0wAJSAEVWdKyLTgf8AZgNrgDNUNXpIcsPre99RHaBZie3ZT3LVIsbFRR3vuWq1ZRVXjXBULd5VqxdV7b449yxYzYdXee2ZHXuG6+ppVGmnxXmvqh6tqnPd77i80qMmuCJb01y1TBanXjiRYtL4IEC1reO7bvXnVuoS2lcbqo53z7IOQ3ol00muWlxe6cxoRLQqK7EjBxItToSrFmNx4qxFkoUJ3z8pqlYqa+2xGfp0jCrtEo4Cd4vIYpcLGuLzStcgIueKyCIRWbRp06bIi+cRjo6NqiVcPsq6VHK3BTtAy/UOZVw4OinKlhRVGylrnQXyCT6bRuw36mnXDNB3q+p6EXkVcI+IPB3cqaoqIpH/dap6NXA1wNy5cyOPCeZVaxZZ+nGGI6Jq0Ran/q9+1JKLEDXIM/7aYVGFLVBlO2bgqRFPWyyOqq533xuBXwDH4fJKA4TySo/hPu0dOTCU1MYJnBYVHKguRxIvlOBx4e1w3UbKtX1FwecJilYCxxvxtFw4IjJFRKb528AHgaeo5pWG2rzSGe4R+NG0fpzo8qS/zI3aOEF3rM6ihYIDwaiahtonlUGeSSMFyloTPEgKYwOMlAK2zTRURzsszkzgIRF5AlgI3KGqvyY+r3QGAlG1MVa2EYmuWlIbh6A7Fh0wCH5XgwW1L305ZhsiLE5MB2hUcGCkXK4rv+Anj3PL723cGrShjaOqq4G3RJRvJiKv9BjvlbuvPurgQKn+hU0KR0d1gIbds8qqcwlRtXIoOBDX3qnUsxxoEzkLfvvSfm5f2s8Zb2vesifdSieFo5tGHiMHshA15GYkEOqqddVqj4sd5BkSQE27pcGogig30duur/tISROtaREYGimzc+9Ipj+uxRROYLud//VRbZyRqDZOOf0gTw2VBUPOSf04weCAEhZOfTh6pFwufIDgkdWbedM374rNmZdEMRMSSiDnQBv/76NctaD7E3TH4seq1btwcS99UlQtLM50rlq1/kUMTw+4YUXTJo4b9bmFFI6PRmZWax3p2zhRIwdqv6t/DDQUEIgXQDlkcWr3VbeDAvOtdamkNedEWc9uZ8fuEQD2MeF41Lhqbfz/jurHiWzjlBu3cYJDcGrbKkRuQ3xfDYQibpEuZbluukHR2FGxOKOXQTGFE5PMr9UMjyS0cbSRq+YOiyjXOFctZvSBf18J5Tmo1DMmbD5ScOEM7Bmmt0eYPL531OcWUjg+HdnGKdW/9NEzQOPaOCFXLWHoTF37J+Y83w0Lnh6OqkVZz25nx+4Rpk3sq+YaHwUFjap1Rjw6clpBZDi6PhlH0iDPuFByqVzbVqqJqpVCHaAR1iQchQu6cM1u4/xx82Db5/wM7BnO5KZBUYVTs1hB+0xO1F/p2naH/601bhvUj1KuDQ4EwschVy1u8GZJw/0/1TpVhKPVUMpIqVyJqqlq3YDVkVKZi3/+ZOa81H922QOjXhay2ezYM5IpMAAFFY6PajtjanGN7mhXza9peMp0fdCgNiJWY3FCblwwJVQpMIQmHNL2rUk4CufXdaSkddZzybpt3LTwj3zllieiHz4F/nKQ7cIsToeS2MaR2myd9ZZGI7/D7aFS4Hd9Xw0B4VQtUClkmfx6esN3qDumVNY66+mfnSal8OK1W1jhlkv0r9cJeG0cszgVEtaVaimNwtGlCDHEtXGqL2p9oz9opcIdm6Vy9Tp+dcoht63qqlFTVrE4ZW3Yxlm5YYANO6ITu3/sqkc45V9/y8Yde1i5YYDdw6XEa7WKrYNDTJ88PtO5BRVOVTnt7QBtFI4OuGoh16zS/qmYIPeltRlxgh2i9e2Y6u+RUlVg4SBCxeLEiK5UrnfV9g7X/v7A/AUcf+n9lePPu3ExS9ZtqznmXf9yPx+Yv4DdQ+0VznCpzLotg2wdHGL/KSacSNoajo4a5FmqiqW2HyfZ4lQtUn2AoWJVyhr78gc7TktaOzfHF3ipHAgOhIUTepbBoZG6Z/OPf3Hbbu588iXOv/Hx2n8Pd589Y7Q4I6XymPqVvv7Lp3jPtx9guKQcYMKpEpw63U5vOslV8xr50SKC+sGpwTZFuI0TfMHDw3H8fcGRAOHoW7CNU6lnYMhNVBsn6G6FI5d7R5KFMRhjcdZtGeSni19IPBfghMse5Lh59zY8Lo47nuyvbE/PKJxCdoB2zMiBhLFqNW2TskZYljjLUxtJC4ano6YOBIMDvVI9TkMi8Y6pXssTWrmyHXY7g+5WuM2yY0/VGkWJaPOu6GSH/+0Hj/Di9j38xZsPYuK4+N789dt2x+6LYtmL25nQ18vrXjUVqH0vsgqnkBbHp+3Bgcj5OFWXq2plqu2WRm2d8OS8YEAgOapWrgYjAhE2qO3H8UUUDEeH2ziqWmM1du6pddt27K52bO7aWy+cuCyh/qpxWweHIvc3YsOOPXxw/m/q+pY+dMVDnPjd37B11xB/3DxY88fFhBNAOmRGTtR8lqqrpgGr0riNUxuOrl4v7ObFzfr0RFQ9J9JVC7Vrqm5erXCGS1pjZXaEhDMQ+L1rb31baOOO5PS6m3emE07YRfzlH9bz7IadXPe7NZHHn3T5Av7ssgdq/mjM3GdiqnuFKaZwEhbPbSWNXLVaS4Err/2us0ARIeegqxaXEirYAVoKWaZKcEC1IuxgOLpU1hrrOVwqV1y1ksLOgDhUtWYozc4o4Qwkr0e6ZVe8cIKu30DEtcME673RWbpg2av3LYhwRORkEXlGRFaJSOY0uNABwYGEvGpK9CDPxm2c8JCbcFQtcK+aSFqo36gmquZbHGrEUgq4bcM149bKFVdt99BIZUIYeA3/RhYn6KpF/RsluWrbB6v32rardqybL9LgH5aXd0Zbt0njevnuGXWpL1LTUcIRkV7ge8ApwFHAJ0XkqFFfp9kVy0jSDNDaNk5gxID/rTG/Q1bUE0HgZQ9anEB4OrgdPi44yNO3iK5Q7sMAAAYESURBVMOl+DbOUKnM7mHvJR0cKtW0cXburQppuFSOsTjVlzmqMzTJVdsaEE5YYP2ujRQUZlx76j+/+E4+euwhsfdphHTSlFgReSdwiaqe5H5fDKCq/xx1/Ny5c3XRokV15RsH9nDcvPuYMW0Cm3furRvv1SrG9UpdNCpY5m9PHt9LX49U2gpzXjWVtVsGGRopM6Gvh1nTJ7PSjevad9I49pnUx7otXmRp5j4T2DiwF1VvQtb0KeNZu3kQgAOnTmDr4BClsjJ1Qh+C5970iLfPf4H9evT2SCVQMW1iH6WyFwTo6xH2mzy+8tf78AOn8PLOvQzsGaG3Rzhw6ng2uHbL7AMms233MNsGhxGBV+8zsfJC+4zv66lYmtceOIXeHu9Pnf+MB0wZH9to3z1c4oWt3rMfvN+kmrk0L27bza6hEpPG9XLI/pMAT9hRUbjl3zqJyeOTg8oisjiwKEANnRaOPhgIJu56AXh78ACXa/pcgFmzZkVe5MApEzj7XbPZsGMPgjBxXC+7h0eYPL6PwaERJvb1MlQqIyL0uf+0kbI3TqvH5QLo7ZFKr/y43h72jHgvkOBZAQF6e3rYM1yir1cqWUOD1yuVy/T19NAj1QjfSLlcuX9ZlUnj+ip/vSf29bK3VEZVmTNzKlPG97HLdTQe+eppjHf1AJh72PTKPUSECX09lY7FY2ftX92HMGl8b6XDctK4PvaMlFBVent6GNcj7BkpeeXDJRCYELhPsH69PT30it8/Nc2r70gZRekRYVxvT6UNMsE9o6ryVvfvLCIMu+f2/12C/UNvOGgfhNphSVG89bD9K/+WQebMnMrEvt5K3X2OmbUfve7/brisHDlzWkPRNKLThNOQNLmje3qEb374jS2tl/HKoqPaOMB6IJjt7hBXZhgdRacJ5/fAHBE5XETGA2fi5ZQ2jI6io1w1VR0RkQuAu4Be4FpVXdbmahlGHR0lHABVvRO4s931MIwkOs1VM4yuwIRjGBkw4RhGBkw4hpGBjhpyM1pEZBOwNmb3gcDLLaxOqyjqc0HnPdthqjojakdXCycJEVkUN86omynqc0F3PZu5aoaRAROOYWSgyMK5ut0VyImiPhd00bMVto1jGHlSZItjGLlhwjGMDBRSOM1M+NFqRORaEdkoIk8FyqaLyD0istJ97+/KRUSucM+5VESObV/NkxGRQ0XkARFZLiLLRORCV96Vz1Y44TQr4UcbuQ44OVR2EXCfqs4B7nO/wXvGOe5zLnBVi+qYhRHgK6p6FPAO4Hz3/9KVz1Y44QDHAatUdbWqDgE3A6e1uU6pUdUFwJZQ8WnA9W77euD0QPkN6vEosJ+IHNSamo4OVe1X1cfd9gCwAi/HRFc+WxGFE5Xw4+A21aVZzFRVP1P4S8BMt92Vzyois4FjgMfo0mcronAKjXr9B13bhyAiU4GfAV9S1R3Bfd30bEUUThETfmzw3RT3vdGVd9Wzisg4PNHcqKo/d8Vd+WxFFE4RE37cBpzlts8Cbg2Uf9ZFoN4BbA+4PR2FeMvkXQOsUNXvBnZ157P5y0YU6QOcCjwLPAf8fbvrM8q63wT0A8N4fv05wAF4EaeVwL3AdHes4EUQnwOeBOa2u/4Jz/VuPDdsKbDEfU7t1mezITeGkYEiumqGkTsmHMPIgAnHMDJgwjGMDJhwDCMDJpyCICKzgyOqA+X/1mWDXLuCjssdbTQXVf18u+tQRMziFIs+EblRRFaIyE9FZLKIPCgicwFEZKeIzBORJ0TkURGZ6co/ISJPufIF7X2E7sCEUyyOBK5U1T8BdgDnhfZPAR5V1bcAC4AvuPJvACe58r9sVWW7GRNOsVinqg+77X/HG+YSZAi43W0vBma77YeB60TkC3jrEhkNMOEUi/D4qfDvYa2OsSrh2riq+kXga3ijkReLyAG51rIAmHCKxSy35D3Ap4CH0pwkIkeo6mOq+g1gE7XD+Y0ITDjF4hm8ufwrgP1JP0//MhF50oWzfwc8kVcFi4KNjjaMDJjFMYwMmHAMIwMmHMPIgAnHMDJgwjGMDJhwDCMDJhzDyMD/B/3YQzJ2/9AoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Using Histogram Equalization Method\n",
        "hist = cv2.calcHist(gray_img, [0], None, [256], [0, 256])\n",
        "plt.subplot(121)\n",
        "plt.title(\"Image1\")\n",
        "plt.xlabel('bins')\n",
        "plt.ylabel(\"No of pixels\")\n",
        "plt.plot(hist)\n",
        "plt.show()\n",
        "gray_img_eqhist = cv2.equalizeHist(gray_img)\n",
        "hist = cv2.calcHist(gray_img_eqhist, [0], None, [256], [0, 256])\n",
        "plt.subplot(121)\n",
        "plt.title(\"Image2\")\n",
        "plt.xlabel('bins')\n",
        "plt.ylabel(\"No of pixels\")\n",
        "plt.plot(hist)\n",
        "plt.show()\n",
        "# gray_img_eqhist = Image.fromarray(gray_img_eqhist)\n",
        "# gray_img_eqhist.show()"
      ],
      "id": "cc116358"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b2ed6b6"
      },
      "outputs": [],
      "source": [
        "# Using CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "gray_img_eqhist = cv2.equalizeHist(gray_img)\n",
        "clahe = cv2.createCLAHE(clipLimit = 40)\n",
        "gray_img_clahe = clahe.apply(gray_img_eqhist)\n",
        "# gray_img_clahe = Image.fromarray(gray_img_clahe)\n",
        "# gray_img_clahe.show()"
      ],
      "id": "6b2ed6b6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0892859e"
      },
      "outputs": [],
      "source": [
        "# OTSU Binarization \n",
        "ret, thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "# thresh = Image.fromarray(thresh)\n",
        "# thresh.show()\n",
        "\n",
        "# Adaptive Thresholding\n",
        "thresh1 = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 31, 3)\n",
        "thresh2 = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 13, 5)\n",
        "final = np.concatenate((thresh1, thresh2), axis = 1)\n",
        "# final = Image.fromarray(final)\n",
        "# final.show()"
      ],
      "id": "0892859e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09c1f9e5",
        "outputId": "45579a16-da30-45e1-a820-cc37a1fc5a19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3024, 4032, 3)\n",
            "(3024, 4032, 3)\n",
            "Simple Pixel Enhancement MSE =  5915.716875746891\n",
            "(3024, 4032, 3)\n",
            "Linear Pixel Transformation Method MSE =  2008.0117123527652\n",
            "(3024, 4032, 3)\n",
            "Linear Pixel Transformation Method with Gamma Correction MSE =  4416.644503200586\n",
            "(3024, 4032, 3)\n",
            "Histogram Equalization Method =  314.0960210730383\n",
            "(3024, 4032, 3)\n",
            "CLAHE Method MSE =  2928.990424433019\n",
            "(3024, 4032, 3)\n",
            "Adaptive Thresholding Method - MEAN MSE =  13749.713118246269\n",
            "(3024, 4032, 3)\n",
            "Adaptive Thresholding Method - GAUSSIAN MSE =  18437.7777336806\n",
            "(3024, 4032, 3)\n",
            "OTSU Binarization Method  MSE =  6308.470293401247\n"
          ]
        }
      ],
      "source": [
        "# Test-Image\n",
        "original_image = np.asarray(original_image, dtype=np.float64)\n",
        "print(original_image.shape)\n",
        "\n",
        "# Simple Pixel Enhancement\n",
        "print(stack_bright.shape)\n",
        "stack_bright = np.asarray(stack_bright, dtype=np.float64)\n",
        "print(\"Simple Pixel Enhancement MSE = \", mse(stack_bright, original_image))\n",
        "\n",
        "# Linear Pixel Transformation Method\n",
        "print(image_linear_transform.shape)\n",
        "image_linear_transform = np.asarray(image_linear_transform, dtype=np.float64)\n",
        "print(\"Linear Pixel Transformation Method MSE = \", mse(image_linear_transform, original_image))\n",
        "\n",
        "# Linear Pixel Transformation Method with Gamma Correction\n",
        "print(gamma_corrected.shape)\n",
        "gamma_corrected = np.asarray(gamma_corrected, dtype=np.float64)\n",
        "print(\"Linear Pixel Transformation Method with Gamma Correction MSE = \", mse(gamma_corrected, original_image))\n",
        "\n",
        "# Histogram Equalization Method\n",
        "gray_img_eqhist = cv2.cvtColor(gray_img_eqhist, cv2.COLOR_GRAY2BGR)\n",
        "print(gray_img_eqhist.shape)\n",
        "gray_img_eqhist = np.asarray(gray_img_eqhist, dtype=np.float64)\n",
        "print(\"Histogram Equalization Method = \", mse(gray_img_eqhist, original_image))\n",
        "\n",
        "# CLAHE Method\n",
        "gray_img_clahe = cv2.cvtColor(gray_img_clahe, cv2.COLOR_GRAY2BGR)\n",
        "print(gray_img_clahe.shape)\n",
        "gray_img_clahe = np.asarray(gray_img_clahe, dtype=np.float64)\n",
        "print(\"CLAHE Method MSE = \", mse(gray_img_clahe, original_image))\n",
        "\n",
        "# Adaptive Thresholding Method - MEAN\n",
        "thresh1 = cv2.cvtColor(thresh1, cv2.COLOR_GRAY2BGR)\n",
        "print(thresh1.shape)\n",
        "thresh1 = np.asarray(thresh1, dtype=np.float64)\n",
        "print(\"Adaptive Thresholding Method - MEAN MSE = \", mse(thresh1, original_image))\n",
        "\n",
        "# Adaptive Thresholding Method - GAUSSIAN\n",
        "thresh2 = cv2.cvtColor(thresh2, cv2.COLOR_GRAY2BGR)\n",
        "print(thresh2.shape)\n",
        "thresh2 = np.asarray(thresh2, dtype=np.float64)\n",
        "print(\"Adaptive Thresholding Method - GAUSSIAN MSE = \", mse(thresh2, original_image))\n",
        "\n",
        "# OTSU Binarization Method \n",
        "thresh = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)\n",
        "print(thresh.shape)\n",
        "thresh = np.asarray(thresh, dtype=np.float64)\n",
        "print(\"OTSU Binarization Method  MSE = \", mse(thresh, original_image))"
      ],
      "id": "09c1f9e5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2adfd3a",
        "outputId": "b0f8850e-3177-447c-b08b-24c8cf90397a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.006666898727416992\n",
            "(3024, 4032, 3)\n",
            "(3024, 4032, 3)\n",
            "image - 1 is enhanced and the mse for the image was 494.2746377470098\n",
            "0.0072672367095947266\n",
            "(3024, 4032, 3)\n",
            "(3024, 4032, 3)\n",
            "image - 2 is enhanced and the mse for the image was 656.4755195866927\n",
            "0.0071218013763427734\n",
            "(3024, 4032, 3)\n",
            "(3024, 4032, 3)\n",
            "image - 3 is enhanced and the mse for the image was 937.2480539283615\n",
            "0.007174015045166016\n",
            "(3024, 4032, 3)\n",
            "(3024, 4032, 3)\n",
            "image - 4 is enhanced and the mse for the image was 314.0960210730383\n",
            "0.007061004638671875\n",
            "(3024, 4032, 3)\n",
            "(3024, 4032, 3)\n",
            "image - 5 is enhanced and the mse for the image was 764.2819668183631\n",
            "0.007261991500854492\n",
            "(3024, 4032, 3)\n",
            "(3024, 4032, 3)\n",
            "image - 6 is enhanced and the mse for the image was 1036.491627331874\n",
            "0.007086277008056641\n",
            "(3024, 4032, 3)\n",
            "(3024, 4032, 3)\n",
            "image - 7 is enhanced and the mse for the image was 577.8433594952899\n",
            "0.007029056549072266\n",
            "(3024, 4032, 3)\n",
            "(3024, 4032, 3)\n",
            "image - 8 is enhanced and the mse for the image was 417.4194312562988\n",
            "0.0073888301849365234\n",
            "(3024, 4032, 3)\n",
            "(3024, 4032, 3)\n",
            "image - 9 is enhanced and the mse for the image was 1616.4671224778492\n",
            "0.007016181945800781\n",
            "(3024, 4032, 3)\n",
            "(3024, 4032, 3)\n",
            "image - 10 is enhanced and the mse for the image was 390.00074303609046\n",
            "Mean MSE =  720.4598482750869\n"
          ]
        }
      ],
      "source": [
        "# Using Histogram Equalization on Several Images for Testing\n",
        "\n",
        "count = 0\n",
        "total_mse = 0\n",
        "for file_name in os.listdir(store_path):\n",
        "    try:\n",
        "        im_to_enhance = cv2.imread(store_path + '/' + file_name)\n",
        "        im_original = Image.open(path + '/' + file_name[9:])\n",
        "        original = np.asarray(im_original, dtype=np.float64)\n",
        "        gray_img = cv2.cvtColor(im_to_enhance, cv2.COLOR_BGR2GRAY)\n",
        "        start_time = time.time()\n",
        "        result = cv2.equalizeHist(gray_img)\n",
        "        end_time = time.time()\n",
        "        print(end_time - start_time)\n",
        "        result = cv2.cvtColor(result, cv2.COLOR_GRAY2BGR)\n",
        "        result = np.asarray(result, dtype=np.float64)\n",
        "        print(result.shape)\n",
        "        print(original.shape)\n",
        "        current_mse = mse(result, original)\n",
        "        count += 1\n",
        "        print(f\"image - {count} is enhanced and the mse for the image was {current_mse}\")\n",
        "        total_mse += current_mse\n",
        "        result = np.asarray(result, dtype=np.uint8)\n",
        "        im_output = Image.fromarray(result)\n",
        "        im_output.save(enhanced_path + '/enhanced_eq_hist' + file_name[9:])\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    if count >= 10:\n",
        "        break\n",
        "print(\"Mean MSE = \", total_mse / 10)"
      ],
      "id": "d2adfd3a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01cdeebe"
      },
      "outputs": [],
      "source": [
        "# Default parameters for Tan-Triggs\n",
        "rows = gray_img.shape[0]\n",
        "cols = gray_img.shape[1]\n",
        "\n",
        "# Gamma Correction \n",
        "gamma = 0.2\n",
        "\n",
        "# Difference of Gaussian (DoG) Filterings\n",
        "sigma_0 = 1\n",
        "sigma_1 = 2\n",
        "\n",
        "# Contrast Equalization\n",
        "alpha = 0.1\n",
        "tao = 10"
      ],
      "id": "01cdeebe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7a5365f"
      },
      "outputs": [],
      "source": [
        "# Tan - Triggs Method\n",
        "\n",
        "gamma_corrected = gray_img ** gamma\n",
        "kernel_0 = ImageFilter.GaussianBlur(radius=sigma_0)\n",
        "kernel_1 = ImageFilter.GaussianBlur(radius=sigma_1)\n",
        "# kernel_0 = np.ones((3 * sigma_0, 3 * sigma_0))\n",
        "# kernel_1 = np.ones((3 * sigma_1 + 1, 3 * sigma_1 + 1))\n",
        "\n",
        "image_0 = Image.fromarray(gamma_corrected).convert('L').filter(kernel_0)\n",
        "image_1 = Image.fromarray(gamma_corrected).convert('L').filter(kernel_1)\n",
        "\n",
        "image_0 = np.array(image_0)\n",
        "image_1 = np.array(image_1)\n",
        "\n",
        "image = image_0 - image_1\n",
        "\n",
        "image = image / ((np.mean((abs(image.flatten())) ** alpha)) ** (1 / alpha))\n",
        "image = image / (np.mean([np.min(tao * np.ones((1, rows * cols))) ** alpha, np.min(abs(gray_img.flatten().reshape((1, rows * cols)))) ** alpha]) ** (1 / alpha))\n",
        "image = tao * np.tanh(image / tao)\n",
        "\n",
        "max_image = np.max(np.max(image))\n",
        "min_image = np.min(np.min(image))\n",
        "\n",
        "for i in range(image.shape[0]):\n",
        "    for j in range(image.shape[1]):\n",
        "        image[i][j] = math.ceil(((image[i][j] - min_image) / (max_image - min_image)) * 255)\n",
        "image = np.asarray(image, dtype=np.uint8)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
        "display_image = Image.fromarray(image).convert('RGB')\n",
        "display_image.save('/content/tan_triggs_IMG_2838.jpeg')"
      ],
      "id": "e7a5365f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3lR-nobzyQB"
      },
      "outputs": [],
      "source": [
        "# Initializing Image Size for the Model and data arrays for storing the images\n",
        "\n",
        "im_size = 256\n",
        "images_darkened = []\n",
        "images_normal = []"
      ],
      "id": "d3lR-nobzyQB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaGQPXYwEA3Y",
        "outputId": "598984a0-fb78-43d2-e310-818de2f12a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219\n",
            "219\n",
            "Done with 0.2 darkened images.\n",
            "\n",
            "438\n",
            "438\n",
            "Done with 0.1 darkened images.\n",
            "\n",
            "657\n",
            "657\n",
            "Done with 0.3 darkened images.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Obtaining the entire dataset for training and testing purposes\n",
        "\n",
        "for file in os.listdir(path):\n",
        "  if file.endswith('jpeg'):\n",
        "    img_light = cv2.imread(os.path.join(path, file))\n",
        "    img_light = cv2.cvtColor(img_light, cv2.COLOR_BGR2HSV)\n",
        "    img_light = img_light[:, :, 2]\n",
        "    img_light = cv2.resize(img_light, (im_size, im_size))\n",
        "    images_normal.append(img_light)\n",
        "\n",
        "    img_dark_2 = cv2.imread(os.path.join(store_path_2, 'darkened_' + file))\n",
        "    img_dark_2 = cv2.rotate(img_dark_2, rotateCode=cv2.ROTATE_90_CLOCKWISE)\n",
        "    img_dark_2 = cv2.cvtColor(img_dark_2, cv2.COLOR_BGR2HSV)\n",
        "    img_dark_2 = img_dark_2[:, :, 2]\n",
        "    img_dark_2 = cv2.resize(img_dark_2, (im_size, im_size))\n",
        "    images_darkened.append(img_dark_2)\n",
        "\n",
        "print(len(images_normal))\n",
        "print(len(images_darkened)) \n",
        "print(\"Done with 0.2 darkened images.\\n\")  \n",
        "\n",
        "for file in os.listdir(path):\n",
        "  if file.endswith('jpeg'):\n",
        "    img_light = cv2.imread(os.path.join(path, file))\n",
        "    img_light = cv2.cvtColor(img_light, cv2.COLOR_BGR2HSV)\n",
        "    img_light = img_light[:, :, 2]\n",
        "    img_light = cv2.resize(img_light, (im_size, im_size))\n",
        "    images_normal.append(img_light)\n",
        "\n",
        "    img_dark_1 = cv2.imread(os.path.join(store_path_1, 'darkened_' + file))\n",
        "    img_dark_1 = cv2.rotate(img_dark_1, rotateCode=cv2.ROTATE_90_CLOCKWISE)\n",
        "    img_dark_1 = cv2.cvtColor(img_dark_1, cv2.COLOR_BGR2HSV)\n",
        "    img_dark_1 = img_dark_1[:, :, 2]\n",
        "    img_dark_1 = cv2.resize(img_dark_1, (im_size, im_size))\n",
        "    images_darkened.append(img_dark_1)\n",
        "\n",
        "print(len(images_normal))\n",
        "print(len(images_darkened))\n",
        "print(\"Done with 0.1 darkened images.\\n\") \n",
        "\n",
        "for file in os.listdir(path):\n",
        "  if file.endswith('jpeg'):\n",
        "    img_light = cv2.imread(os.path.join(path, file))\n",
        "    img_light = cv2.cvtColor(img_light, cv2.COLOR_BGR2HSV)\n",
        "    img_light = img_light[:, :, 2]\n",
        "    img_light = cv2.resize(img_light, (im_size, im_size))\n",
        "    images_normal.append(img_light)\n",
        "\n",
        "    img_dark_3 = cv2.imread(os.path.join(store_path_3, 'darkened_' + file))\n",
        "    img_dark_3 = cv2.rotate(img_dark_3, rotateCode=cv2.ROTATE_90_CLOCKWISE)\n",
        "    img_dark_3 = cv2.cvtColor(img_dark_3, cv2.COLOR_BGR2HSV)\n",
        "    img_dark_3 = img_dark_3[:, :, 2]\n",
        "    img_dark_3 = cv2.resize(img_dark_3, (im_size, im_size))\n",
        "    images_darkened.append(img_dark_3)\n",
        "\n",
        "print(len(images_normal))\n",
        "print(len(images_darkened))\n",
        "print(\"Done with 0.3 darkened images.\\n\") "
      ],
      "id": "IaGQPXYwEA3Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Klq4shwfsZa"
      },
      "outputs": [],
      "source": [
        "# Normalization and Storage of Data\n",
        "\n",
        "images_darkened = np.array(images_darkened)\n",
        "images_darkened = images_darkened.reshape(-1, im_size, im_size, 1)\n",
        "images_darkened = images_darkened / 255.0\n",
        "images_normal = np.array(images_normal)\n",
        "images_normal = images_normal.reshape(-1, im_size, im_size, 1)\n",
        "images_normal = images_normal / 255.0\n",
        "\n",
        "x_train = images_darkened\n",
        "y_train = images_normal"
      ],
      "id": "0Klq4shwfsZa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwaNkjtrfun1"
      },
      "outputs": [],
      "source": [
        "# Tensorboard Callbacks to monitor the progress of training\n",
        "\n",
        "log_dir_1 = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "%reload_ext tensorboard\n",
        "log_folder = 'log_dir_1'\n",
        "TensorBoard_callbacks = [tf.keras.callbacks.TensorBoard(log_dir=log_folder,\n",
        "                         histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_images=True,\n",
        "                         update_freq='epoch',\n",
        "                         profile_batch=2,\n",
        "                         embeddings_freq=1)]"
      ],
      "id": "YwaNkjtrfun1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGCLHZi4MMpZ",
        "outputId": "ff44024e-cbda-411f-e2db-791ab32a2ad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"TF_image_enhancer_256_size_value_channel\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 1)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 256, 256, 64)      640       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 128)     73856     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256, 256, 128)    512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 128, 128, 128)    0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128, 128, 128)     0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 128)     147584    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 64)      73792     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 128, 128, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, 256, 256, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 256, 256, 1)       577       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 297,217\n",
            "Trainable params: 296,833\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# The Auto - Encoder Model\n",
        "\n",
        "input_layer = Input(shape=(im_size, im_size, 1))\n",
        "\n",
        "# Encoder of Autoencoder\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Decoder of Autoencoder\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Final Model\n",
        "model = Model(inputs=[input_layer], outputs=[output_layer], name='TF_image_enhancer_256_size_value_channel')\n",
        "model.summary()"
      ],
      "id": "eGCLHZi4MMpZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RZcd3UppFE1"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam' , loss='mean_squared_error', metrics=['mae'])"
      ],
      "id": "0RZcd3UppFE1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heT0A0RuSlqQ",
        "outputId": "95dffd8c-f43e-4aca-d010-e76f2a16a241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "66/66 [==============================] - 26s 197ms/step - loss: 0.0320 - mae: 0.1331 - val_loss: 0.0699 - val_mae: 0.2167\n",
            "Epoch 2/10\n",
            "66/66 [==============================] - 9s 133ms/step - loss: 0.0183 - mae: 0.1017 - val_loss: 0.0768 - val_mae: 0.2257\n",
            "Epoch 3/10\n",
            "66/66 [==============================] - 9s 133ms/step - loss: 0.0162 - mae: 0.0958 - val_loss: 0.0872 - val_mae: 0.2413\n",
            "Epoch 4/10\n",
            "66/66 [==============================] - 9s 134ms/step - loss: 0.0146 - mae: 0.0906 - val_loss: 0.0736 - val_mae: 0.2224\n",
            "Epoch 5/10\n",
            "66/66 [==============================] - 9s 133ms/step - loss: 0.0137 - mae: 0.0877 - val_loss: 0.0825 - val_mae: 0.2378\n",
            "Epoch 6/10\n",
            "66/66 [==============================] - 9s 135ms/step - loss: 0.0136 - mae: 0.0877 - val_loss: 0.0524 - val_mae: 0.1869\n",
            "Epoch 7/10\n",
            "66/66 [==============================] - 9s 136ms/step - loss: 0.0128 - mae: 0.0851 - val_loss: 0.0367 - val_mae: 0.1573\n",
            "Epoch 8/10\n",
            "66/66 [==============================] - 9s 137ms/step - loss: 0.0120 - mae: 0.0818 - val_loss: 0.0272 - val_mae: 0.1338\n",
            "Epoch 9/10\n",
            "66/66 [==============================] - 9s 138ms/step - loss: 0.0112 - mae: 0.0790 - val_loss: 0.0218 - val_mae: 0.1216\n",
            "Epoch 10/10\n",
            "66/66 [==============================] - 9s 139ms/step - loss: 0.0106 - mae: 0.0767 - val_loss: 0.0219 - val_mae: 0.1209\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train, validation_split=0.2, epochs=10, batch_size=8, callbacks=TensorBoard_callbacks)"
      ],
      "id": "heT0A0RuSlqQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "Ek1J-ts5POM3",
        "outputId": "a8ea5bd8-8d58-4f22-915e-5a6b3ce2dc38"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir={log_folder}"
      ],
      "id": "Ek1J-ts5POM3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrGFDWffGzhf"
      },
      "outputs": [],
      "source": [
        "model.save('/content/TF_image_enhancer_256_size_value_channel.h5')"
      ],
      "id": "FrGFDWffGzhf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWBr4rxsNCmH"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('/content/TF_image_enhancer_256_size_value_channel_10_epochs.h5', compile=True)"
      ],
      "id": "OWBr4rxsNCmH"
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = cv2.imread('/content/00036_02_0.1s.jpeg')"
      ],
      "metadata": {
        "id": "3u1M2hbLJyfP"
      },
      "id": "3u1M2hbLJyfP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTlXsAcr5Ipl"
      },
      "outputs": [],
      "source": [
        "# Testing and Viewing the Results\n",
        "img = cv2.rotate(test_image, rotateCode=cv2.ROTATE_90_CLOCKWISE)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "img = img[:, :, 2]\n",
        "img = cv2.resize(img, (im_size, im_size))\n",
        "img = img / 255.0\n",
        "img = img.reshape(-1, img.shape[0], img.shape[1], 1)\n",
        "# print(img)\n",
        "or_img = cv2.cvtColor(original_image, cv2.COLOR_BGR2HSV)\n",
        "or_img = or_img[:, :, 2]\n",
        "or_img = cv2.resize(or_img, (im_size, im_size))\n",
        "or_img = or_img / 255.0\n",
        "or_img = or_img.reshape(-1, or_img.shape[0], or_img.shape[1], 1)\n",
        "# print(or_img)"
      ],
      "id": "jTlXsAcr5Ipl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIllgezf5CZj",
        "outputId": "bfaa9b69-f65c-41c3-e6c4-6402cbd42ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0186 - mae: 0.1089\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.018641404807567596, 0.10888467729091644]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "model.evaluate(img, or_img)"
      ],
      "id": "SIllgezf5CZj"
    },
    {
      "cell_type": "code",
      "source": [
        "true_l, true_r, _ = test_image.shape"
      ],
      "metadata": {
        "id": "jfVtXTfar67s"
      },
      "id": "jfVtXTfar67s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKrhtZJdeD9m"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(img)\n",
        "pred = pred * 255\n",
        "pred = np.asarray(pred, dtype=np.uint8)\n",
        "pred = pred[0].reshape((im_size, im_size))\n",
        "dup_img = test_image\n",
        "dup_img = cv2.rotate(dup_img, rotateCode=cv2.ROTATE_90_CLOCKWISE)\n",
        "dup_img = cv2.cvtColor(dup_img, cv2.COLOR_BGR2HSV)\n",
        "dup_img = cv2.resize(dup_img, (im_size, im_size))\n",
        "dup_img[:, :, 2] = pred\n",
        "dup_img = cv2.cvtColor(dup_img, cv2.COLOR_HSV2BGR)\n",
        "dup_img = cv2.resize(dup_img, (true_l, true_r))\n",
        "pred_img = Image.fromarray(dup_img)\n",
        "pred_img.save('/content/predicted_ltsid_1.jpeg')"
      ],
      "id": "rKrhtZJdeD9m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTUUFu2sH45n"
      },
      "outputs": [],
      "source": [
        "img = img * 255\n",
        "img = np.asarray(img, dtype=np.uint8)\n",
        "img = img.reshape((im_size, im_size))\n",
        "dup_img = test_image\n",
        "dup_img = cv2.cvtColor(dup_img, cv2.COLOR_BGR2HSV)\n",
        "dup_img = cv2.resize(dup_img, (im_size, im_size))\n",
        "dup_img[:, :, 2] = img\n",
        "dup_img = cv2.cvtColor(dup_img, cv2.COLOR_HSV2BGR)\n",
        "dup_img = cv2.resize(dup_img, (true_l, true_r))\n",
        "dark_img = Image.fromarray(dup_img)\n",
        "dark_img.save('/content/dark_ltsid_1.jpeg')"
      ],
      "id": "NTUUFu2sH45n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt7NvqIGHdwE"
      },
      "outputs": [],
      "source": [
        "or_img = or_img * 255\n",
        "or_img = np.asarray(or_img, dtype=np.uint8)\n",
        "or_img = or_img.reshape((im_size, im_size))\n",
        "dup_img = original_image\n",
        "dup_img = cv2.resize(dup_img, (im_size, im_size))\n",
        "dup_img[:, :, 2] = or_img\n",
        "dup_img = cv2.resize(dup_img, (true_l, true_r))\n",
        "orig_img = Image.fromarray(dup_img)\n",
        "orig_img.save('/content/original_image.jpeg')"
      ],
      "id": "bt7NvqIGHdwE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9kheBub30kJ"
      },
      "source": [
        "#***Learning to See in the Dark***"
      ],
      "id": "_9kheBub30kJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "My9iTHRD2X6a"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os"
      ],
      "id": "My9iTHRD2X6a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-RX56S82bLt"
      },
      "outputs": [],
      "source": [
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)"
      ],
      "id": "L-RX56S82bLt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUtfzmCi2gP_"
      },
      "outputs": [],
      "source": [
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None"
      ],
      "id": "XUtfzmCi2gP_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN2diA_82jIG"
      },
      "outputs": [],
      "source": [
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)"
      ],
      "id": "QN2diA_82jIG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxX5CZyj2lwk"
      },
      "outputs": [],
      "source": [
        "download_file_from_google_drive('10kpAcvldtcb9G2ze5hTcF1odzu4V_Zvh', 'dataset/Sony.zip')"
      ],
      "id": "DxX5CZyj2lwk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***Adding Rain and Snow***"
      ],
      "metadata": {
        "id": "eYZzzjlZA5xI"
      },
      "id": "eYZzzjlZA5xI"
    },
    {
      "cell_type": "code",
      "source": [
        "def add_snow(image):    \n",
        "  image_HLS = cv2.cvtColor(image, cv2.COLOR_RGB2HLS) ## Conversion to HLS \n",
        "  image_HLS = np.array(image_HLS, dtype=np.float64)     \n",
        "  brightness_coefficient = 2.5     \n",
        "  snow_point = 140 ## increase this for more snow    \n",
        "  image_HLS[:, :, 1][image_HLS[:, :, 1] < snow_point] = image_HLS[:, :, 1][image_HLS[:, :, 1] < snow_point] * brightness_coefficient ## scale pixel values up for channel 1(Lightness)    \n",
        "  image_HLS[:, :, 1][image_HLS[:, :, 1] > 255] = 255 ##Sets all values above 255 to 255    \n",
        "  image_HLS = np.array(image_HLS, dtype=np.uint8)    \n",
        "  image_RGB = cv2.cvtColor(image_HLS, cv2.COLOR_HLS2RGB) ## Conversion to RGB    \n",
        "  return image_RGB"
      ],
      "metadata": {
        "id": "uIY65cNeBAAI"
      },
      "id": "uIY65cNeBAAI",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_lines(imshape, slant, drop_length):    \n",
        "  drops = []    \n",
        "  for i in range(100): ## If You want heavy rain, try increasing this        \n",
        "    if slant < 0:            \n",
        "      x = np.random.randint(slant, imshape[1])        \n",
        "    else:            \n",
        "      x = np.random.randint(0, imshape[1] - slant)        \n",
        "    y = np.random.randint(0, imshape[0] - drop_length)        \n",
        "    drops.append((x, y))    \n",
        "  return drops            "
      ],
      "metadata": {
        "id": "GwnzrsbzBhja"
      },
      "id": "GwnzrsbzBhja",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_rain(image):        \n",
        "  imshape = image.shape    \n",
        "  slant_extreme = 10    \n",
        "  slant = np.random.randint(-slant_extreme, slant_extreme)     \n",
        "  drop_length = 75    \n",
        "  drop_width = 10    \n",
        "  drop_color = (200, 200, 200) ## a shade of gray    \n",
        "  rain_drops = generate_random_lines(imshape, slant, drop_length)        \n",
        "  for rain_drop in rain_drops:        \n",
        "    cv2.line(image, (rain_drop[0], rain_drop[1]), (rain_drop[0] + slant, rain_drop[1] + drop_length), drop_color, drop_width)    \n",
        "    image = cv2.blur(image, (7, 7)) ## rainy view are blurry        \n",
        "    brightness_coefficient = 0.5 ## rainy days are usually shady     \n",
        "    image_HLS = cv2.cvtColor(image, cv2.COLOR_RGB2HLS) ## Conversion to HLS    \n",
        "    image_HLS[:, :, 1] = image_HLS[:, :, 1] * brightness_coefficient ## scale pixel values down for channel 1(Lightness)    \n",
        "    image_RGB = cv2.cvtColor(image_HLS, cv2.COLOR_HLS2RGB) ## Conversion to RGB    \n",
        "  return image_RGB"
      ],
      "metadata": {
        "id": "AKvIKJkqCiTU"
      },
      "id": "AKvIKJkqCiTU",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saved in Rain_Images\n",
        "\n",
        "for file_name in os.listdir(path):\n",
        "    try:\n",
        "        img = cv2.imread(path + '/' + file_name)\n",
        "        im_output = add_rain(img)\n",
        "        cv2.imwrite(rain_path + '/rain_' + file_name, im_output)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "metadata": {
        "id": "JE-iKqsO-rI_"
      },
      "id": "JE-iKqsO-rI_",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saved in Snow_Images\n",
        "\n",
        "for file_name in os.listdir(path):\n",
        "    try:\n",
        "        img = cv2.imread(path + '/' + file_name)\n",
        "        im_output = add_snow(img)\n",
        "        cv2.imwrite(snow_path + '/snow_' + file_name, im_output)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "metadata": {
        "id": "7ON6i5CC-vY4"
      },
      "id": "7ON6i5CC-vY4",
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}